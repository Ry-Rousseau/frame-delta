{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c81f863",
   "metadata": {},
   "source": [
    "### Framing classifier using BERT \n",
    "\n",
    "This model will shift towards a multi-class classification. The goal is to generate a model that can be used in social network analysis and social media content analysis while being fairly lightweight.\n",
    "Downstream, it will be evaluated on a gold standard media frame corpus dataset. https://aclanthology.org/P15-2072.pdf\n",
    "\n",
    "As the v1 notebook, this will contain all the experimental code and EDA for the initial stage of model development, carrying on from the lessons found in the topic classifier v2.\n",
    "\n",
    "Frame prediction is much more complicated task than single topic prediction. We will see how far we can get with a base roBerta model with long-doc policy. Then we will likely expand to a larger model or combine BERTs. Data filtering to specific issue areas may also prove useful. \n",
    "\n",
    "Generic frames include non-issue specific frames that are generalizable across issues areas. The media frame corpus dataset lays out a set of 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c222c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import transformers\n",
    "load_dotenv()  # looks for .env in current directory or parent\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d67cf",
   "metadata": {},
   "source": [
    "### Sample the data, ensure same categories as the media frames corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb726b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Column(name='text_generic_frame', type_code=1009), Column(name='gpt_topic', type_code=25), Column(name='political_leaning', type_code=25), Column(name='title', type_code=25), Column(name='maintext', type_code=25))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_generic_frame</th>\n",
       "      <th>gpt_topic</th>\n",
       "      <th>political_leaning</th>\n",
       "      <th>title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Health and safety, Policy prescription and ev...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>left_lean</td>\n",
       "      <td>The extreme heat is impacting Friday night foo...</td>\n",
       "      <td>Mansfield ISD is making changes within the foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[External regulation and reputation, Policy pr...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>left_lean</td>\n",
       "      <td>House Republicans are in chaos again, fighting...</td>\n",
       "      <td>WASHINGTON — A band of hard-right agitators, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Crime and punishment, Health and safety]</td>\n",
       "      <td>Disaster &amp; Accidents</td>\n",
       "      <td>left_lean</td>\n",
       "      <td>Frisco ISD student struck, killed while riding...</td>\n",
       "      <td>A 15-year-old Frisco ISD student was struck an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Cultural identity, External regulation and re...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>left_lean</td>\n",
       "      <td>CBS announces exclusive weeklong residency in ...</td>\n",
       "      <td>CBS has announced an exclusive residency in La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Cultural identity, Policy prescription and ev...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>left</td>\n",
       "      <td>Joe Jonas Wears Wedding Ring Amid Sophie Turne...</td>\n",
       "      <td>LOADINGERROR LOADING\\nJoe Jonas left his fans ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text_generic_frame             gpt_topic  \\\n",
       "0  [Health and safety, Policy prescription and ev...                Sports   \n",
       "1  [External regulation and reputation, Policy pr...              Politics   \n",
       "2          [Crime and punishment, Health and safety]  Disaster & Accidents   \n",
       "3  [Cultural identity, External regulation and re...                Sports   \n",
       "4  [Cultural identity, Policy prescription and ev...         Entertainment   \n",
       "\n",
       "  political_leaning                                              title  \\\n",
       "0         left_lean  The extreme heat is impacting Friday night foo...   \n",
       "1         left_lean  House Republicans are in chaos again, fighting...   \n",
       "2         left_lean  Frisco ISD student struck, killed while riding...   \n",
       "3         left_lean  CBS announces exclusive weeklong residency in ...   \n",
       "4              left  Joe Jonas Wears Wedding Ring Amid Sophie Turne...   \n",
       "\n",
       "                                        article_text  \n",
       "0  Mansfield ISD is making changes within the foo...  \n",
       "1  WASHINGTON — A band of hard-right agitators, b...  \n",
       "2  A 15-year-old Frisco ISD student was struck an...  \n",
       "3  CBS has announced an exclusive residency in La...  \n",
       "4  LOADINGERROR LOADING\\nJoe Jonas left his fans ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to server \n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    dbname=os.getenv(\"DB_NAME\"),\n",
    "    user=os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\")\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# key: set the seed\n",
    "cur.execute(\"SELECT setseed(0.42)\")\n",
    "\n",
    "# Do our join in database - NOTE this is with a POLITICS FILTER\n",
    "cur.execute(f\"\"\"\n",
    "           SELECT a.text_generic_frame, a.gpt_topic, a.political_leaning, a.title,  \n",
    "           b.maintext\n",
    "           FROM mm_framing_full a\n",
    "           JOIN newsarticles b ON a.url = b.url\n",
    "           ORDER BY RANDOM()\n",
    "            LIMIT 200000\n",
    "            \"\"\")\n",
    "\n",
    "result= cur.fetchall()\n",
    "\n",
    "print(cur.description)\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "df = pd.DataFrame(result, columns=[\"text_generic_frame\", \"gpt_topic\", \"political_leaning\", \"title\", \"article_text\"])\n",
    "\n",
    "del result\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d18d7",
   "metadata": {},
   "source": [
    "### Sample the data, ensure same categories as the media frames corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f65075b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['num_words'] = df['article_text'].str.split().str.len()\n",
    "\n",
    "df['num_words'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faaa2f5",
   "metadata": {},
   "source": [
    "### Initial data filtering\n",
    "* Keep the same minimum length requirement  \n",
    "* Noting the above histogram, we might exclude articles that are over 1000 words. This also gives BERT a fighting chance initially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5cc043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 200000\n",
      "Filtered rows: 149437\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original rows: {len(df)}\")\n",
    "\n",
    "df_filtered = df[(df['num_words'] > 100) & (df['num_words'] <= 1500)]\n",
    "df = df_filtered.dropna()\n",
    "df = df.reset_index()\n",
    "\n",
    "print(f\"Filtered rows: {len(df_filtered)}\")\n",
    "\n",
    "del df_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d7962",
   "metadata": {},
   "source": [
    "### Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd1b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_generic_frame\n",
      "Quality of life                                  36726\n",
      "Policy prescription and evaluation               33434\n",
      "Economic                                         30851\n",
      "Crime and punishment                             29117\n",
      "Political                                        28981\n",
      "Legality, constitutionality and jurisprudence    28369\n",
      "Public opinion                                   27756\n",
      "Fairness and equality                            21469\n",
      "Health and safety                                21195\n",
      "Cultural identity                                20661\n",
      "Security and defense                             19008\n",
      "External regulation and reputation               15831\n",
      "Capacity and resources                           11343\n",
      "Other                                            10798\n",
      "Morality                                          6710\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# all_frames = set(df['text_generic_frame'].sum())\n",
    "\n",
    "# counts = df['text_generic_frame'].explode().value_counts()\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# print(counts)\n",
    "\n",
    "# phew - at least the times when it's not part of the 15 categories seem to be extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162eecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows where the list is NOT exactly ['Other']\n",
    "# df = df[df['cleaned_frames'].apply(lambda x: x != ['Other'])]\n",
    "# print(f\"Rows remaining: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd665dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append title\n",
    "df['article_text'] = df['title'] + \"\\n\" + df['article_text']\n",
    "\n",
    "# Then append TOPIC \n",
    "df['article_text'] = \"TOPIC: \" + df['gpt_topic'] + \"\\n\" + df['article_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef67ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic Topics: ['Economic', 'Capacity and resources', 'Legality, constitutionality and jurisprudence']\n",
      "TOPIC: Legal\n",
      "Trump has been unable to get bond for $464 million judgment, his lawyers say\n",
      "Former President Donald Trump has not been able to get a bond to secure the $464 million civil fraud judgment against him and his co-defendants, his lawyers said in a court filing Monday.\n",
      "Trump and his company need to post a bond for the full amount by next week in order to stop New York Attorney General Letitia James from being able to collect while he appeals. They've asked an appeals court to step in in the meantime and said Monday that they have not had any success getting a bond.\n",
      "\"Defendants’ ongoing diligent efforts have proven that a bond in the judgment’s full amount is 'a practical impossibility,'\" the filing said. \"These diligent efforts have included approaching about 30 surety companies through 4 separate brokers.\"\n",
      "Their efforts, including “countless hours negotiating with one of the largest insurance companies in the world,” have proven that “obtaining an appeal bond in the full amount” of the judgment “is not possible under the circumstances presented,” the filing said.\n",
      "The other bond companies will not “accept hard assets such as real estate as collateral,” but “will only accept cash or cash equivalents (such as marketable securities),” the filing said. The lawyers also noted those companies typically “require collateral of approximately 120% of the amount of the judgment” — which would total about $557 million.\n",
      "\"In addition, sureties would likely charge bond premiums of approximately 2 percent per year with two years in advance—an upfront cost over $18 million,\" the filing said. That $18 million would not be recoverable even if Trump wins his appeal.\n",
      "In all, the filing said, the \"actual amount of cash or cash equivalents required 'to collateralize the bond and have sufficient capital to run the business and satisfy its other obligations' approach[es] $1 billion.\"\n",
      "While the filing says Trump can't afford the bond, it also argues that the attorney general doesn't have to worry about being able to collect her judgment.\n",
      "\"Defendants’ real estate holdings — including iconic properties like 40 Wall Street, Doral Miami, and Mar-a-Lago, — greatly exceed the amount of the judgment. Such assets are impossible to secrete or dispose of surreptitiously, leaving the plaintiff effectively secured during the pendency of an appeal,\" the filing said.\n",
      "Trump's team also argued the $464 million penalty is \"grossly disproportional\" and cited the argument they made throughout the monthslong trial that \"there are no victims, as there were no damages and no financial losses.\"\n",
      "In a filing last month, Trump's lawyers asked that the bond amount be reduced to $100 million, but Monday's filing argues he shouldn't have to put up any bond at all.\n",
      "James' office has argued that Trump should put up the full amount.\n",
      "A 30-day automatic stay of the judgment handed down by Judge Arthur Engoron is set to expire March 25, at which point James would be clear to start seizing Trump's assets unless the appeals court steps in.\n",
      "James would not need an additional court order to start collecting in New York, where Trump has his company and a large number of real estate assets, but those efforts could be complicated by any mortgages or debts he has on those properties. It’s unclear what properties or assets James might look to seize.\n",
      "Steven Cheung, a spokesman for Trump's campaign, said in a statement that the judgment is \"unjust, unconstitutional\" and \"un-American.\"\n",
      "\"A bond of this size would be an abuse of the law,\" he said.\n",
      "Trump asked that if the state Appellate Division denies his request, the judges enter a temporary stay so he can try to make his case to the state's highest court, the Court of Appeals.\n",
      "Engoron handed down his judgment last month after finding Trump and his company had repeatedly committed fraud by overinflating personal financial statements that he used to secure bank loans and insurance policies. James' office said there were years when Trump's assets were overvalued by more than $2 billion.\n",
      "Trump maintained he did nothing wrong and testified that, if anything, his properties were undervalued.\n",
      "The judge hit Trump and his co-defendants with a judgment saying they had to pay over $350 million — an amount that ballooned to $464 million with pre-judgment interest. Of that amount on the date the judgment was entered, the vast majority, or about $454 million, was against Trump and his companies.\n",
      "That amount has grown since — the judgment against Trump will increase at a daily rate of nearly $112,000 until it’s paid off because of interest on the penalty, according to the attorney general’s office.\n",
      "The filing Monday seeking to freeze the entire $464 million was filed on behalf of Trump and his co-defendants, including his sons Don Jr. and Eric, who've been running the Trump Organization since their father first went to the White House.\n"
     ]
    }
   ],
   "source": [
    "index = 34\n",
    "print(f\"Generic Topics: {df.iloc[index]['text_generic_frame']}\")\n",
    "print(df.iloc[index]['article_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e416c",
   "metadata": {},
   "source": [
    "### Tokenization + long doc policy\n",
    "* At this point, I'm happy with the dataset quality, so we'll move forward with the defined pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d64562c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1565 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# choosing a base tokenizer model, this won't \n",
    "model_name = \"FacebookAI/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# generally want to keep the tokenizations in a separate variable rather than adding them back to the dataframe (for efficiency, taking advantage of the batching features of the huggingface tokenizer)\n",
    "\n",
    "encodings = tokenizer(df['article_text'].tolist(),                      # we opt to dynamically do padding later with head/tail strategy\n",
    "                      # hence we also don't need truncation here\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e94ac191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 28332, 2371] 512\n",
      "[0, 28332, 2371] 512\n",
      "[0, 28332, 2371] 506\n",
      "[0, 28332, 2371] 512\n",
      "[0, 28332, 2371] 512\n",
      "[0, 28332, 2371] 512\n",
      "[0, 28332, 2371] 512\n",
      "[0, 28332, 2371] 256\n",
      "[0, 28332, 2371] 512\n",
      "[0, 28332, 2371] 274\n"
     ]
    }
   ],
   "source": [
    "# Code to set the unique head and tail of the articles\n",
    "head_len = 320\n",
    "tail_len = 190\n",
    "content_len = head_len + tail_len          \n",
    "max_len = content_len + 2  # [CLS] + [SEP]      \n",
    "\n",
    "cls_id = tokenizer.cls_token_id\n",
    "sep_id = tokenizer.sep_token_id\n",
    "pad_id = tokenizer.pad_token_id\n",
    "\n",
    "for i, ids in enumerate(encodings[\"input_ids\"]):\n",
    "    # ClS and Sep Id's are present in tokenized values, so do this\n",
    "    if len(ids) >= 2 and ids[0] == cls_id and ids[-1] == sep_id:\n",
    "        ids = ids[1:-1]\n",
    "\n",
    "    # Head+tail on the content tokens\n",
    "    if len(ids) > content_len:\n",
    "        head = ids[:head_len]\n",
    "        tail = ids[-tail_len:]\n",
    "        ids = head + tail\n",
    "\n",
    "    # Add specials back\n",
    "    ids = [cls_id] + ids + [sep_id]\n",
    "\n",
    "    # Build attention mask (1 for real tokens)\n",
    "    mask = [1] * len(ids)\n",
    "\n",
    "    # Pad (or truncate)\n",
    "    if len(ids) < max_len:\n",
    "        pad_n = max_len - len(ids)\n",
    "        ids = ids + [pad_id] * pad_n\n",
    "        mask = mask + [0] * pad_n\n",
    "    else:\n",
    "        ids = ids[:max_len]\n",
    "        mask = mask[:max_len]\n",
    "\n",
    "    # Write back\n",
    "    encodings[\"input_ids\"][i] = ids\n",
    "    encodings[\"attention_mask\"][i] = mask\n",
    "\n",
    "# quick sanity check\n",
    "for ids, mask in zip(encodings[\"input_ids\"][:10], encodings[\"attention_mask\"][:10]):\n",
    "    assert len(ids) == 512 and len(mask) == 512\n",
    "    print(ids[:3], sum(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d0002",
   "metadata": {},
   "source": [
    "### PyTorch Dataset Creation\n",
    "\n",
    "Using `torch.utils.data.Dataset` and `torch.utils.data.DataLoader`\n",
    "\n",
    "[Pytorch data tutorial](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "* Key change from topic classifier workflow is to establish multi-class prediction\n",
    "\n",
    "To do this, need to change:\n",
    "* label shape, we need it to be a binary vector (list of 0 and 1s) the length of total categories (15), we can use https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\n",
    "* standard multi-label loss functions (like `BCEWithLogitsLoss`) need targets to be floats, so we change our label tensor dtype to torch.float\n",
    "* continue filtering out the non-tensor data stuff in batch loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0b00940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148593, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['encoders/mlb_15_classes_r4.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# Firstly we binarize the frame labels\n",
    "\n",
    "official_labels = [\n",
    "    \"Economic\", \"Capacity and resources\", \"Morality\", \"Fairness and equality\",\n",
    "    \"Legality, constitutionality and jurisprudence\", \"Policy prescription and evaluation\",\n",
    "    \"Crime and punishment\", \"Security and defense\", \"Health and safety\",\n",
    "    \"Quality of life\", \"Cultural identity\", \"Public opinion\", \"Political\",\n",
    "    \"External regulation and reputation\", \"Other\"\n",
    "]\n",
    "\n",
    "#  Initialize and Fit\n",
    "mlb = MultiLabelBinarizer(classes=official_labels)\n",
    "mlb.fit(df['text_generic_frame']) # Fit on your data (or just the list of labels)\n",
    "\n",
    "# Transform data into the binary matrix\n",
    "# creates a big matrix of 0s and 1s\n",
    "labels_matrix = mlb.transform(df['text_generic_frame'])\n",
    "\n",
    "# sanity check\n",
    "# labels_matrix.shape should be (Num_Rows, 15)\n",
    "print(labels_matrix.shape)\n",
    "\n",
    "# we should also save the binarizer object in case we need it later after training a good model\n",
    "import joblib\n",
    "joblib.dump(mlb, 'encoders/mlb_15_classes_r4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d243a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the below to record the raw text, but filter this out in batch processing since it's not a tensor\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NewsArticleDataset(Dataset):\n",
    "    def __init__(self, encodings, labels_matrix, df):\n",
    "        \"\"\"\n",
    "        encodings: result from tokenizer(text, truncation=True, padding=True)\n",
    "        labels_matrix: Your Multi-Hot encoded vectors (List or Tensor)\n",
    "        df: The pandas DataFrame containing metadata (gpt_topic, title, etc.)\n",
    "        \"\"\"\n",
    "        # Tensor-ready data\n",
    "        self.input_ids = encodings['input_ids']\n",
    "        self.attention_mask = encodings['attention_mask']\n",
    "        self.labels = labels_matrix \n",
    "\n",
    "        # Raw Text / Metadata (Stored as standard Python lists)\n",
    "        # convert to list for indexing robustness\n",
    "        self.article_text = df['article_text'].tolist()\n",
    "        self.titles = df['title'].tolist()\n",
    "        self.gpt_topics = df['gpt_topic'].tolist()\n",
    "        self.political_leanings = df['political_leaning'].tolist()\n",
    "        self.num_words = df['num_words'].tolist()\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        dict_to_return = {\n",
    "            # Tensors for the model\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float), # ensure float for loss calcs\n",
    "            \n",
    "            # Raw data for analysis/filtering later\n",
    "            'article_text': self.article_text[idx],\n",
    "            'title': self.titles[idx],\n",
    "            'gpt_topic': self.gpt_topics[idx],\n",
    "            'political_leaning': self.political_leanings[idx],\n",
    "            'num_words': self.num_words[idx]\n",
    "        }\n",
    "        return dict_to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ce5b46",
   "metadata": {},
   "source": [
    "### Creating the test/train/val split\n",
    "\n",
    "We can't so easily stratify like we did with the topic classifier, since we have so many unique combinations of labels, which seems to overwhelm the scikitlearn base stratifier. However, stratification is still quite important to expose the model appropriately to all the different combinations.\n",
    "\n",
    "We can use a specialized method in iterative stratification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbdb0b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 118874, Val: 14854, Test: 14865\n"
     ]
    }
   ],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# 1. Setup your data\n",
    "# Ensure 'labels_matrix' is your MultiLabelBinarizer output (the 0s and 1s matrix)\n",
    "# Shape should be (Num_Samples, Num_Classes)\n",
    "N = len(labels_matrix)\n",
    "X_indices = np.zeros(N) # Dummy input just for the splitter to index\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SPLIT 1: Separate Train (80%) from Temp (20%)\n",
    "# ---------------------------------------------------------\n",
    "msss1 = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n",
    "\n",
    "# We use next(iter(...)) to grab the first split immediately\n",
    "train_idx, temp_idx = next(iter(msss1.split(X_indices, labels_matrix)))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SPLIT 2: Separate Val (10%) from Test (10%)\n",
    "# We split 'temp' in half (0.5 of 0.2 = 0.1 total)\n",
    "# ---------------------------------------------------------\n",
    "# Subset the labels for just the temp part\n",
    "temp_labels = labels_matrix[temp_idx]\n",
    "temp_dummy_X = np.zeros(len(temp_idx))\n",
    "\n",
    "msss2 = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.50, random_state=42)\n",
    "\n",
    "# Get indices relative to the temp_idx list (0 to len(temp_idx))\n",
    "relative_val_idx, relative_test_idx = next(iter(msss2.split(temp_dummy_X, temp_labels)))\n",
    "\n",
    "# MAP BACK: Convert relative indices (0, 1, 2...) to original dataset indices (500, 12, 99...)\n",
    "val_idx = temp_idx[relative_val_idx]\n",
    "test_idx = temp_idx[relative_test_idx]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# BUILD DATASET\n",
    "# ---------------------------------------------------------\n",
    "# Note: Use your NEW binary labels here, not the old ID list\n",
    "full_dataset = NewsArticleDataset(encodings, labels_matrix, df) \n",
    "\n",
    "train = Subset(full_dataset, train_idx)\n",
    "val   = Subset(full_dataset, val_idx)\n",
    "test  = Subset(full_dataset, test_idx)\n",
    "\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd785b0",
   "metadata": {},
   "source": [
    "### Creating the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62e9671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously I was just parsing out the data set meta data when loading the batches, but there's a much more elegant way of doing this \n",
    "# we can make use of the dataloader collate_fn \n",
    "\n",
    "import torch\n",
    "\n",
    "def parse_out_metadata_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of dictionaries (the output of __getitem__ for each item in the batch)\n",
    "    \"\"\"\n",
    "    # Initialize the output dictionary\n",
    "    batch_out = {}\n",
    "    \n",
    "    # Handle Tensors: Stack them (Turn list of 1D tensors into one 2D tensor)\n",
    "    # We explicitly list the keys we know are tensors\n",
    "    tensor_keys = ['input_ids', 'attention_mask', 'labels']\n",
    "    \n",
    "    for key in tensor_keys:\n",
    "        # stack stacks along a new dimension (batch dimension)\n",
    "        batch_out[key] = torch.stack([item[key] for item in batch])\n",
    "        \n",
    "    # Handle Text/Metadata: Keep them as simple lists\n",
    "    # We collect everything else that isn't a tensor key\n",
    "    all_keys = batch[0].keys()\n",
    "    text_keys = [k for k in all_keys if k not in tensor_keys]\n",
    "    \n",
    "    for key in text_keys:\n",
    "        batch_out[key] = [item[key] for item in batch]\n",
    "        \n",
    "    return batch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b97c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate the data loader, they rely on dataset + indices\n",
    "batch_size = 32\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# data loaders handle our raw (non-tensor) article text automatically\n",
    "train_loader = DataLoader(train, \n",
    "                          batch_size = batch_size, # number of articles to be fed into the model at once\n",
    "                          shuffle = True, \n",
    "                          pin_memory= True,\n",
    "                          collate_fn= parse_out_metadata_collate_fn)\n",
    "val_loader = DataLoader(val, \n",
    "                          batch_size = batch_size, # number of articles to be fed into the model at once\n",
    "                          shuffle = False, # false so eval is deterministic and reproducible\n",
    "                          pin_memory= True,\n",
    "                          collate_fn = parse_out_metadata_collate_fn)\n",
    "test_loader = DataLoader(test, \n",
    "                          batch_size = batch_size, # number of articles to be fed into the model at once\n",
    "                          shuffle = False,  # false, as above\n",
    "                          pin_memory= True,\n",
    "                          collate_fn = parse_out_metadata_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4782703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Democrat Donna Deegan Flips Mayor's Office In Jacksonville, Florida\", 'Aurora passes proposal to bring back reserve police officers after 18 years without a program', \"Johnson faces uphill climb to win back GOP rebels before November; here's what they want\", 'Top House rep takes aim at college tax-free status over students anti-Israel stance', \"Conservatives Rip Joe Biden's Debt Limit Deal With GOP\", 'Jack Smith gives notice of evidence he wants to use against Trump', 'Missouri judge to decide if voters can be required to show ID to cast ballot', 'Thai police arrest 2nd teenager for defaming monarchy amid renewed debate over rigorous law', 'United Bodegas of America announces plan to arm workers in NYC shops', 'Putin met Prigozhin days after mercenary chief led mutiny, Kremlin says', 'Protesters on Auraria Campus in downtown Denver detained', 'Stuart Varney: Republican candidates race for second place behind Trump', \"Princess Diana Fans Joke She Ruined Weather for King's Coronation\", 'Israeli forces withdraw from Jenin as rockets fired from Gaza', 'Navalny team says Russia threatened his mother with ultimatum to avoid burial at Arctic prison', 'New Mexico governor should face federal charges for gun control power grab: former prosecutor', 'Veterans help Americans leaving Gaza: ‘Easier time getting people out of Afghanistan’', \"Nancy Mace defends vote to oust McCarthy as unity opportunity: 'He was fired for not keeping promises'\", 'Schiff ‘not backing down’ in face of Republican bid to expel him from Congress', 'Pandas may return to California, China’s Xi says', 'Eye on Politics: Senator Cornyn on the standoff between governments at the border', 'Donald Trump Jr., Kimberly Guilfoyle Attack Ron DeSantis', 'Debt limit talks at standstill as GOP, White House face ‘real differences’', 'Japanese journalist barred from entering Hong Kong without clear reason, newspaper says', 'David Oh could make history in Philadelphia mayor election', 'Delegation from west African bloc meets Niger’s ousted president', \"Governor Newsom says California's budget deficit has grown to nearly $32 billion\", 'Why Biden is helping Javier Milei, Trump’s favorite Latin American leader', 'How an eccentric English tech guru helped guide Allende’s socialist Chile', 'Harvard College sees drop in early applicants compared to last year', 'Don Noels obituary', 'Save the whales? More like kill US energy production']\n"
     ]
    }
   ],
   "source": [
    "# Let's test on a batch as a sanity check\n",
    "# grab a batch using iterator next()\n",
    "#batch = next(iter(train_loader))\n",
    "\n",
    "# print(batch['title'])\n",
    "# so now we have our useful metadata in our batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbdc36",
   "metadata": {},
   "source": [
    "### Begin training loop\n",
    "\n",
    "* This is our initial run with truncated text on a complicated multi-class classification with roBERTa, so expectations are not super high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa7a39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a clean state, hard reset the GPU state\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f94669",
   "metadata": {},
   "source": [
    "For our optimizer setup, we'll shift to using multi label classification. The key difference is that we're using sigmoids instead of softmax in the classification layer, and we're allowing multiple nodes to fire as 'true predicted class'.\n",
    "\n",
    "Multi-Label: Uses `BCEWithLogitsLoss` (Binary Cross Entropy). This treats every single category as an independent Yes/No question. It allows \"Politics\" to be 0.9 and \"Crime\" to also be 0.9 simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96b9d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = labels_matrix.shape[1]\n",
    "\n",
    "# Initialize Model with explicit problem_type\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\" # forces BCEWithLogitsLoss internally\n",
    ")\n",
    "model.to('cuda')\n",
    "\n",
    "# define optimizer, same as with single classification\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=3e-5, \n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "# Implement weighted loss \n",
    "num_positives = torch.tensor(labels_matrix.sum(axis=0), dtype=torch.float)\n",
    "num_negatives = len(labels_matrix) - num_positives\n",
    "\n",
    "# get the realtive imbalance as a fractional value\n",
    "pos_weight = (num_negatives / (num_positives + 1e-5)).to('cuda')\n",
    "\n",
    "# Define the Loss Function with these weights\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210a400",
   "metadata": {},
   "source": [
    "Very key decision is now how **we define a correct prediction**, as fitting the entire row is a very strict requirement. \n",
    "\n",
    "Basically there's three choices\n",
    "* Exact match ratio (fitting the whole row - very strcit)\n",
    "* Hamming Accuracy (what % of individual boxes are correct?)\n",
    "    * downside is that if a label has many 0's, model scores highly just by predicting 0\n",
    "* F1 score - harmonic mean of precision and recall - much better, as usual, for this kind of task. ignores the easy zeros and focuses on the ones\n",
    "    * We can use scikit-learn to implement this, `sklearn.metrics`\n",
    "\n",
    "We go with F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e55e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0/3715 | Current Loss: 0.8871\n",
      "  Batch 500/3715 | Current Loss: 0.6008\n",
      "  Batch 1000/3715 | Current Loss: 0.6595\n",
      "  Batch 1500/3715 | Current Loss: 0.6126\n",
      "  Batch 2000/3715 | Current Loss: 0.5123\n",
      "  Batch 2500/3715 | Current Loss: 0.6046\n",
      "  Batch 3000/3715 | Current Loss: 0.4780\n",
      "  Batch 3500/3715 | Current Loss: 0.5519\n",
      "Epoch 0 | Train Loss: 0.5956\n",
      "Epoch 0 | val_loss=0.4130 | F1 (Micro)=0.7147 | F1 (Macro)=0.6957 | Exact Match=0.0787\n",
      "--> New Best Score! (Old: 0.0000 | New: 0.7147)\n",
      "--> Saving model to saved_models/framing_training_runs/best_model_state.bin...\n",
      "  Batch 0/3715 | Current Loss: 0.4409\n",
      "  Batch 500/3715 | Current Loss: 0.4793\n",
      "  Batch 1000/3715 | Current Loss: 0.5162\n",
      "  Batch 1500/3715 | Current Loss: 0.6059\n",
      "  Batch 2000/3715 | Current Loss: 0.5140\n",
      "  Batch 2500/3715 | Current Loss: 0.5074\n",
      "  Batch 3000/3715 | Current Loss: 0.5200\n",
      "  Batch 3500/3715 | Current Loss: 0.4905\n",
      "Epoch 1 | Train Loss: 0.5308\n",
      "Epoch 1 | val_loss=0.3956 | F1 (Micro)=0.7243 | F1 (Macro)=0.7037 | Exact Match=0.0949\n",
      "--> New Best Score! (Old: 0.7147 | New: 0.7243)\n",
      "--> Saving model to saved_models/framing_training_runs/best_model_state.bin...\n",
      "  Batch 0/3715 | Current Loss: 0.4750\n",
      "  Batch 500/3715 | Current Loss: 0.5680\n",
      "  Batch 1000/3715 | Current Loss: 0.4836\n",
      "  Batch 1500/3715 | Current Loss: 0.4643\n",
      "  Batch 2000/3715 | Current Loss: 0.4911\n",
      "  Batch 2500/3715 | Current Loss: 0.4583\n",
      "  Batch 3000/3715 | Current Loss: 0.5046\n",
      "  Batch 3500/3715 | Current Loss: 0.4799\n",
      "Epoch 2 | Train Loss: 0.4975\n",
      "Epoch 2 | val_loss=0.3839 | F1 (Micro)=0.7322 | F1 (Macro)=0.7127 | Exact Match=0.1103\n",
      "--> New Best Score! (Old: 0.7243 | New: 0.7322)\n",
      "--> Saving model to saved_models/framing_training_runs/best_model_state.bin...\n",
      "  Batch 0/3715 | Current Loss: 0.4348\n",
      "  Batch 500/3715 | Current Loss: 0.4827\n",
      "  Batch 1000/3715 | Current Loss: 0.4086\n",
      "  Batch 1500/3715 | Current Loss: 0.5037\n",
      "  Batch 2000/3715 | Current Loss: 0.4873\n",
      "  Batch 2500/3715 | Current Loss: 0.4467\n",
      "  Batch 3000/3715 | Current Loss: 0.4687\n",
      "  Batch 3500/3715 | Current Loss: 0.5647\n",
      "Epoch 3 | Train Loss: 0.4627\n",
      "Epoch 3 | val_loss=0.3905 | F1 (Micro)=0.7336 | F1 (Macro)=0.7130 | Exact Match=0.1082\n",
      "--> New Best Score! (Old: 0.7322 | New: 0.7336)\n",
      "--> Saving model to saved_models/framing_training_runs/best_model_state.bin...\n",
      "  Batch 0/3715 | Current Loss: 0.4267\n",
      "  Batch 500/3715 | Current Loss: 0.4018\n",
      "  Batch 1000/3715 | Current Loss: 0.3562\n",
      "  Batch 1500/3715 | Current Loss: 0.3878\n",
      "  Batch 2000/3715 | Current Loss: 0.4432\n",
      "  Batch 2500/3715 | Current Loss: 0.3994\n",
      "  Batch 3000/3715 | Current Loss: 0.4176\n",
      "  Batch 3500/3715 | Current Loss: 0.3037\n",
      "Epoch 4 | Train Loss: 0.4295\n",
      "Epoch 4 | val_loss=0.3877 | F1 (Micro)=0.7361 | F1 (Macro)=0.7176 | Exact Match=0.1175\n",
      "--> New Best Score! (Old: 0.7336 | New: 0.7361)\n",
      "--> Saving model to saved_models/framing_training_runs/best_model_state.bin...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "epochs = 5\n",
    "best_val_f1 = 0.0\n",
    "save_path = \"saved_models/framing_training_runs/best_model_state.bin\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ==========================\n",
    "    # TRAINING\n",
    "    # ==========================\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, batch in enumerate(train_loader):  # enumerate gives us i      \n",
    "        model_input_keys = ['input_ids', 'attention_mask', 'labels']\n",
    "\n",
    "        # \"Move to CUDA if key is in list, ELSE keep original value 'v'\"\n",
    "        batch = {k: (v.to(\"cuda\") if k in model_input_keys else v) for k, v in batch.items()}\n",
    "        \n",
    "        article_text = batch.pop(\"article_text\", None)\n",
    "        \n",
    "        # 2) forward pass \n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"] #,\n",
    "            #labels=batch[\"labels\"] comment out in implementing weighted loss\n",
    "        )\n",
    "\n",
    "        # calculate the custom weighted loss\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits, batch[\"labels\"]) \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 3) zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4) backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5) step\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(f\"  Batch {i}/{len(train_loader)} | Current Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Print training loss for the epoch\n",
    "    print(f\"Epoch {epoch} | Train Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # ==========================\n",
    "    # VALIDATION\n",
    "    # ==========================\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # 1. Lists to store results for the whole epoch\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model_input_keys = ['input_ids', 'attention_mask', 'labels']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # 2. Safer Move to GPU\n",
    "            batch_tensors = {k: v.to(\"cuda\") for k, v in batch.items() if k in model_input_keys}\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=batch_tensors[\"input_ids\"],\n",
    "                attention_mask=batch_tensors[\"attention_mask\"],\n",
    "                labels=batch_tensors[\"labels\"],\n",
    "            )\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "            # 3. Get Predictions\n",
    "            logits = outputs.logits\n",
    "            # Sigmoid + Threshold\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            \n",
    "            # 4. Collect inputs for sklearn (Move to CPU -> Numpy)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(batch_tensors[\"labels\"].cpu().numpy())\n",
    "\n",
    "    # 5. Stack and Calculate Metrics\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    # Micro F1: Global calculation (Total True Positives / Total Positives). Best for imbalanced data.\n",
    "    val_f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
    "\n",
    "    # Macro F1: Calculate F1 for each class separately, then average. Good to see if rare classes are failing.\n",
    "    val_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    # Exact Match Ratio: Strict \"All or Nothing\" accuracy (optional but good context)\n",
    "    val_exact_acc = (all_preds == all_labels).all(axis=1).mean()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch} | val_loss={val_loss/len(val_loader):.4f} \"\n",
    "        f\"| F1 (Micro)={val_f1_micro:.4f} | F1 (Macro)={val_f1_macro:.4f} | Exact Match={val_exact_acc:.4f}\"\n",
    "    )\n",
    "    \n",
    "    # checkpointing\n",
    "    if val_f1_micro > best_val_f1:\n",
    "        print(f\"--> New Best Score! (Old: {best_val_f1:.4f} | New: {val_f1_micro:.4f})\")\n",
    "        print(f\"--> Saving model to {save_path}...\")\n",
    "        best_val_f1 = val_f1_micro\n",
    "        # Only save the weights (state_dict) to save space\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        print(f\"--> No improvement. Best is still {best_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb630a0d",
   "metadata": {},
   "source": [
    "#### Training run notes\n",
    "- Dry run with n = 5000 completed in about 3 min, no memory issues, can likely increase batch to 32 post restart and GPU clear\n",
    "\n",
    "### Run 1 - 70000 N, batch_size 32, epochs 10, time = 178 min, \n",
    "* GPU memory was stable, could potentially go to batchsize 64\n",
    "* Training improvement flattened after a few epochs. same behavior as in the topic classifier. \n",
    "* Based on the eval results, our threshold (0.5) seems appropriate, but a single threshold for all classes doesn't seem to fit. This is intuitive, as rarer classes may require a lower threshold\n",
    "    * lowering the global threshold to 0.4 would trade-off some precision for higher recall, bringing them into balance, however we have a mix between two kinds of classification error\n",
    "    * the model is a bit 'shy' for some classes, especially for some rarer classes like cultural identity and policy perscription/evaluation   \n",
    "    * model is too 'lenient' for some classes, specifically fairness and equality, political - though overall it is generally too 'shy'\n",
    "    * In order to address these points, we can run a post-processing optimization (not hyperparameter optimization to save on local compute) to find the optimal per-class threshold using the validation set. We extract the raw confidence level (sigmoids values), run a grid search over reasonable thresholds for 'class occurence', choose value which maximizes the F1 score. \n",
    "* Let's leave the bigbird/longformer approach for now, and see how much more juice we can squeeze out of BERT with the above step\n",
    "* We should additionally implement a more flexible **weighted loss** to try and bake in varying confidence-levels into the model training per-class, so it truly integrates the logic we've been seeing with the post-training class evaluations. This is not mutually exclusive to the post-processing threshold fine-tuning. Likely that just changing the internal weights means we don't have to change the thresholds as aggressively. In fact, that is likely to be the case as the model learns better features. Both combined will generate an effective model. \n",
    "\n",
    "### Run 2 - 70000 N, batch_size 32, epochs 5 - implementing weighted loss\n",
    "Epoch 4 | val_loss=0.4143 | F1 (Micro)=0.7277 | F1 (Macro)=0.7066 | Exact Match=0.1034\n",
    "\n",
    "* Seems like Run two wasn't all that better than Run 1\n",
    "\n",
    "| Metric               | Run 1 (Optimized Thresholds) | Run 2 (Weighted + Optimized) | Verdict                   |\n",
    "| -------------------- | ---------------------------: | ---------------------------: | ------------------------- |\n",
    "| Micro F1 (Global)    |                        0.731 |                        0.729 | Tie (Statistical noise)   |\n",
    "| Macro F1 (Per Class) |                        0.706 |                        0.706 | Tie                       |\n",
    "| Recall (Macro)       |                        0.753 |                        0.769 | Weighted Loss Win (+1.6%) |\n",
    "| Precision (Macro)    |                        0.666 |                        0.656 | Unweighted Win (+1.0%)    |\n",
    "| Training Stability   |                Overfit early |           Overfit at Epoch 4 | Similar                   |\n",
    "\n",
    "\n",
    "* It's like we've hit the limit of what BERT + head/tail truncation can learn for this complex task in this dataset.\n",
    "* Now it seems reasonable to level up to the longformer or bigbird approach\n",
    "\n",
    "* **but I'm not totally convinced just yet** - what if we work on a subset of the data, like just articles classified as 'politics', will this improve the performance? Sub-class filtering\n",
    "\n",
    "### Run 3 - ONLY POLITICS Articles - testing a hypothesis on subject expert model\n",
    "### same params as runs 2 but with as many politics articles as we have in database\n",
    "Epoch 9 | val_loss=0.4818 | F1 (Micro)=0.7330 | F1 (Macro)=0.6772 | Exact Match=0.1002\n",
    "\n",
    "* This was a pretty successful experiment, check out the related notes doc in the notes folder\n",
    "* From this, we can probably even squeeze out more performance by adding the string of the topic like \"TOPIC: POLITICS\" to the start of the input text\n",
    "\n",
    "Next steps will be to level-up to Longformer `allenai/longformer-base-4096` and setting global attention mask for the [CLS] token, taking advantage of much larger input size\n",
    "\n",
    "Alternative is to use hierarchical bert architecture, but we'll leave that for now. Perhaps revisit later\n",
    "\n",
    "### Run 4 (Run 5 overall - with run 4 longformer) - N 150000 - Appending Topic to Article Start, Kept 'non-observation' rows\n",
    "- THis is basically here to see how much of the longformer performance is truly due to long-context and global attention inclusion as methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c1cd1d",
   "metadata": {},
   "source": [
    "### Evaluation of test results, inspecting individual class performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f93de7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Get predictions on the TEST set\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move to GPU\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items() if k in ['input_ids', 'attention_mask', 'labels']}\n",
    "        \n",
    "        outputs = model(**batch) ## double asteriks means unpack dict into keyword args, outputs = model(input_ids=batch[\"input_ids\"],attention_mask=batch[\"attention_mask\"],labels=batch[\"labels\"],)\n",
    "        logits = outputs.logits\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float() # Standard threshold\n",
    "        \n",
    "        test_preds.append(preds.cpu().numpy())\n",
    "        test_labels.append(batch['labels'].cpu().numpy())\n",
    "\n",
    "test_preds = np.vstack(test_preds)\n",
    "test_labels = np.vstack(test_labels)\n",
    "\n",
    "# Generate Report\n",
    "report = classification_report(test_labels, test_preds, target_names=official_labels, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9697adea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_clean_items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# counts per label\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m counts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43mall_clean_items\u001b[49m)\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m      4\u001b[0m out \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      5\u001b[0m     df_report\n\u001b[0;32m      6\u001b[0m       \u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m       \u001b[38;5;241m.\u001b[39massign(count\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m d: d\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmap(counts)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInt64\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      8\u001b[0m       \u001b[38;5;241m.\u001b[39mreset_index(names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m out\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_clean_items' is not defined"
     ]
    }
   ],
   "source": [
    "# counts per label\n",
    "counts = pd.Series(all_clean_items).value_counts()\n",
    "\n",
    "out = (\n",
    "    df_report\n",
    "      .sort_values(\"f1-score\", ascending=False)\n",
    "      .assign(count=lambda d: d.index.map(counts).astype(\"Int64\"))\n",
    "      .reset_index(names=\"label\")\n",
    ")\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90ba9c2",
   "metadata": {},
   "source": [
    "#### Running grid-search over thresholds for classification for each of the 15 cats using validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed42f5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.1766e-01, 5.5384e-01, 3.4634e-03, 3.3086e-02, 2.9837e-02, 8.1552e-01,\n",
      "         6.7229e-01, 8.3156e-01, 2.1186e-01, 8.2530e-01, 9.4045e-01, 6.3303e-01,\n",
      "         3.7815e-01, 4.3720e-01, 9.7547e-01],\n",
      "        [6.0916e-01, 3.9411e-03, 1.3917e-03, 3.4970e-01, 9.1945e-01, 9.0406e-01,\n",
      "         3.3880e-02, 2.7326e-02, 9.9605e-01, 5.1909e-01, 3.0651e-03, 9.7702e-02,\n",
      "         4.1621e-02, 1.2501e-01, 4.0094e-02],\n",
      "        [1.9792e-02, 2.5656e-03, 4.4823e-01, 8.0491e-01, 7.8455e-01, 1.5256e-02,\n",
      "         8.7927e-01, 3.7716e-02, 2.1409e-03, 2.4351e-02, 9.4903e-03, 4.6172e-01,\n",
      "         9.9699e-01, 3.2415e-02, 1.3273e-02],\n",
      "        [1.3570e-02, 3.7822e-03, 1.9890e-03, 4.4925e-03, 4.6490e-02, 5.4875e-02,\n",
      "         9.9635e-01, 9.8573e-01, 5.4253e-02, 1.6272e-01, 7.8528e-03, 1.8679e-01,\n",
      "         1.6983e-02, 8.0731e-03, 5.4793e-02],\n",
      "        [1.3985e-01, 1.3223e-01, 8.1487e-03, 2.9729e-01, 9.8660e-01, 6.6373e-01,\n",
      "         1.4596e-01, 9.8239e-01, 4.9116e-03, 1.3499e-02, 6.2362e-01, 2.5562e-01,\n",
      "         7.7193e-01, 9.9147e-01, 5.4661e-02],\n",
      "        [9.1495e-01, 3.8094e-02, 2.6832e-02, 4.9561e-01, 9.9288e-01, 9.8840e-01,\n",
      "         2.2983e-01, 2.2546e-01, 7.6516e-01, 8.3077e-01, 5.8209e-01, 5.1304e-01,\n",
      "         5.3175e-01, 9.1869e-01, 5.9968e-01],\n",
      "        [6.9796e-03, 3.5274e-03, 2.1485e-02, 5.1655e-03, 2.1465e-03, 4.1185e-02,\n",
      "         4.3272e-03, 5.8893e-03, 9.4002e-01, 9.7133e-01, 5.3636e-01, 1.3481e-01,\n",
      "         6.9117e-03, 1.0410e-02, 6.7803e-01],\n",
      "        [9.8471e-01, 8.1770e-01, 1.3278e-03, 9.5634e-01, 1.1898e-01, 9.1009e-01,\n",
      "         4.3023e-01, 1.4907e-02, 1.1802e-02, 1.5221e-01, 6.4956e-03, 2.8395e-01,\n",
      "         1.1793e-01, 2.6926e-02, 7.1967e-01],\n",
      "        [3.1931e-03, 1.1068e-03, 4.0409e-03, 9.7742e-02, 2.9196e-01, 2.2514e-02,\n",
      "         9.9723e-01, 6.9828e-01, 3.1423e-02, 2.0084e-01, 5.7245e-03, 8.1208e-02,\n",
      "         7.3951e-03, 1.3632e-03, 1.6599e-02],\n",
      "        [9.5115e-01, 9.6551e-01, 1.8728e-02, 2.7119e-01, 5.2085e-01, 8.4427e-01,\n",
      "         7.4662e-01, 4.8327e-02, 9.2070e-01, 5.2758e-01, 3.1157e-02, 8.0515e-01,\n",
      "         5.2279e-01, 2.8960e-01, 5.4675e-01],\n",
      "        [9.9854e-01, 9.7882e-01, 8.4742e-04, 6.8729e-01, 3.0483e-01, 9.8603e-01,\n",
      "         1.1620e-01, 1.7997e-01, 4.4732e-01, 8.8276e-01, 1.7264e-01, 8.9260e-02,\n",
      "         8.9391e-02, 4.7994e-01, 8.2359e-01],\n",
      "        [9.9447e-01, 9.0463e-01, 3.6818e-04, 2.2316e-01, 2.1466e-01, 9.7612e-01,\n",
      "         6.2090e-01, 7.3361e-01, 4.2428e-01, 9.0587e-01, 7.9326e-01, 7.6928e-01,\n",
      "         7.9499e-01, 8.0989e-01, 3.3972e-01],\n",
      "        [9.9719e-01, 9.7948e-01, 8.4358e-04, 4.5750e-01, 4.6178e-01, 9.8418e-01,\n",
      "         5.0565e-01, 4.9573e-01, 2.3413e-01, 9.6473e-01, 7.6389e-01, 5.7786e-01,\n",
      "         7.4904e-01, 8.5825e-01, 1.2259e-01],\n",
      "        [9.8970e-01, 7.5929e-01, 3.1228e-02, 8.3884e-01, 1.9001e-02, 4.2455e-01,\n",
      "         1.5888e-01, 3.0425e-03, 1.7397e-02, 9.8990e-01, 5.4870e-01, 7.2239e-01,\n",
      "         6.1859e-01, 7.9150e-02, 8.1951e-02],\n",
      "        [1.8427e-01, 2.2675e-02, 5.2950e-01, 3.4814e-02, 6.9569e-02, 5.5117e-01,\n",
      "         6.7466e-02, 7.4149e-02, 9.5300e-01, 9.9480e-01, 9.9410e-01, 6.0704e-01,\n",
      "         3.1672e-01, 2.0766e-01, 8.9287e-01],\n",
      "        [4.5208e-01, 4.9174e-01, 2.7849e-03, 4.4426e-01, 1.5415e-01, 3.7178e-01,\n",
      "         1.8594e-01, 9.1914e-01, 9.8813e-01, 8.1945e-01, 7.2285e-01, 7.3093e-01,\n",
      "         5.4463e-01, 4.6211e-01, 2.2707e-01],\n",
      "        [2.2834e-01, 1.7208e-02, 9.9372e-01, 1.9042e-01, 7.3070e-02, 2.6273e-01,\n",
      "         4.0607e-02, 5.1355e-03, 9.3423e-01, 9.7985e-01, 1.9135e-01, 2.2241e-01,\n",
      "         2.9556e-01, 2.5016e-02, 3.7805e-01],\n",
      "        [6.2256e-02, 4.3260e-03, 2.1017e-03, 1.0061e-02, 2.9961e-03, 4.0294e-02,\n",
      "         9.7687e-03, 1.6316e-01, 1.1235e-02, 9.4360e-01, 3.5377e-01, 7.7956e-01,\n",
      "         1.7375e-01, 2.9609e-03, 8.3781e-01],\n",
      "        [9.8469e-01, 9.5921e-01, 6.4041e-03, 1.1141e-02, 3.5126e-03, 1.0059e-01,\n",
      "         9.3529e-03, 7.0348e-03, 6.6686e-03, 7.9177e-01, 6.5139e-02, 1.8367e-01,\n",
      "         1.5581e-01, 1.1296e-02, 1.0421e-02],\n",
      "        [4.0186e-01, 4.4243e-01, 6.8808e-04, 6.8519e-01, 9.4765e-01, 9.8086e-01,\n",
      "         8.6604e-02, 4.2047e-01, 9.8638e-01, 3.4449e-01, 2.3705e-01, 8.1467e-01,\n",
      "         7.6058e-01, 9.3120e-01, 3.2211e-02],\n",
      "        [3.6864e-01, 1.0939e-02, 2.1528e-03, 6.0433e-01, 9.9797e-01, 4.3488e-01,\n",
      "         9.4828e-01, 7.5655e-03, 1.5946e-03, 2.0738e-02, 2.3335e-03, 2.5704e-01,\n",
      "         7.9814e-01, 4.6220e-02, 5.6843e-03],\n",
      "        [2.0146e-03, 2.7354e-03, 2.7295e-03, 5.1565e-03, 1.9111e-02, 1.1819e-02,\n",
      "         9.8844e-01, 8.7146e-01, 5.1064e-01, 7.3360e-02, 3.2497e-03, 8.9540e-02,\n",
      "         5.8349e-03, 3.4070e-03, 2.4860e-02],\n",
      "        [1.7116e-01, 2.0952e-02, 2.6100e-02, 5.1532e-01, 2.2882e-01, 2.8088e-01,\n",
      "         9.9840e-01, 4.4896e-01, 8.8969e-04, 1.1388e-01, 5.1075e-01, 9.3121e-01,\n",
      "         7.6915e-01, 3.6854e-01, 4.1255e-02],\n",
      "        [7.3089e-02, 1.0543e-02, 9.7545e-01, 8.2530e-01, 9.7483e-01, 4.1493e-01,\n",
      "         5.3951e-02, 3.0900e-02, 7.1305e-02, 1.9869e-01, 7.4846e-01, 2.2900e-01,\n",
      "         1.7257e-01, 5.1817e-02, 9.7985e-01],\n",
      "        [5.7329e-02, 3.7163e-03, 3.0254e-03, 2.5953e-01, 9.9492e-01, 1.3397e-01,\n",
      "         4.9740e-01, 2.4195e-03, 2.4419e-03, 3.9807e-03, 4.9679e-03, 1.2510e-01,\n",
      "         9.5098e-01, 1.3005e-01, 7.7729e-02],\n",
      "        [1.2241e-02, 5.3710e-03, 7.2294e-03, 1.8264e-02, 9.7099e-01, 5.9033e-01,\n",
      "         5.3226e-01, 9.9690e-01, 8.7229e-01, 2.3752e-02, 3.7023e-03, 9.5300e-02,\n",
      "         3.8569e-02, 8.1389e-01, 1.5280e-01],\n",
      "        [5.2054e-01, 7.0406e-01, 2.1132e-01, 7.6368e-02, 9.0383e-02, 6.5030e-01,\n",
      "         8.5031e-02, 1.3129e-01, 6.8066e-01, 9.8571e-01, 9.9640e-01, 7.1708e-01,\n",
      "         6.6859e-01, 4.2705e-01, 9.1228e-01],\n",
      "        [6.5603e-01, 2.1178e-01, 9.8991e-03, 2.1599e-01, 3.4335e-01, 7.0603e-01,\n",
      "         5.7295e-01, 7.7123e-01, 8.6304e-01, 8.2870e-01, 8.1386e-01, 6.8047e-01,\n",
      "         5.4478e-01, 7.5695e-01, 9.2621e-01],\n",
      "        [2.7678e-02, 2.1722e-03, 9.2835e-02, 2.6592e-02, 1.0096e-01, 1.2072e-01,\n",
      "         9.0820e-03, 1.1610e-02, 1.4934e-02, 8.8678e-01, 9.8952e-01, 1.8459e-01,\n",
      "         3.1017e-01, 1.3390e-02, 8.0699e-01],\n",
      "        [1.3901e-02, 2.4754e-03, 8.7604e-03, 6.1361e-03, 4.6952e-03, 6.9918e-02,\n",
      "         6.6520e-03, 4.7953e-04, 8.2262e-01, 9.4562e-01, 6.6208e-01, 5.9640e-01,\n",
      "         3.4256e-02, 5.0160e-03, 1.3981e-01],\n",
      "        [3.6743e-01, 5.2907e-01, 9.8860e-01, 9.2266e-01, 8.3919e-01, 3.8751e-01,\n",
      "         7.9227e-01, 3.0317e-02, 2.6539e-02, 7.0130e-01, 5.3576e-01, 6.0896e-01,\n",
      "         6.6030e-01, 1.5282e-01, 1.3839e-01],\n",
      "        [4.0912e-01, 6.6446e-03, 2.2843e-03, 5.0815e-03, 2.3355e-03, 1.7931e-01,\n",
      "         1.1845e-02, 3.1030e-02, 4.1233e-02, 9.2733e-01, 8.3484e-01, 9.3856e-01,\n",
      "         3.2490e-01, 1.2864e-02, 9.5543e-01]], device='cuda:0')\n",
      "\n",
      "Finding optimal thresholds per class...\n",
      "  Economic                                 Best: 0.35 (Val F1: 0.797)\n",
      "  Capacity and resources                   Best: 0.75 (Val F1: 0.624)\n",
      "  Morality                                 Best: 0.75 (Val F1: 0.649)\n",
      "  Fairness and equality                    Best: 0.55 (Val F1: 0.723)\n",
      "  Legality, constitutionality and jurisprudence Best: 0.45 (Val F1: 0.806)\n",
      "  Policy prescription and evaluation       Best: 0.40 (Val F1: 0.762)\n",
      "  Crime and punishment                     Best: 0.40 (Val F1: 0.798)\n",
      "  Security and defense                     Best: 0.75 (Val F1: 0.761)\n",
      "  Health and safety                        Best: 0.45 (Val F1: 0.788)\n",
      "  Quality of life                          Best: 0.35 (Val F1: 0.807)\n",
      "  Cultural identity                        Best: 0.55 (Val F1: 0.733)\n",
      "  Public opinion                           Best: 0.40 (Val F1: 0.678)\n",
      "  Political                                Best: 0.45 (Val F1: 0.770)\n",
      "  External regulation and reputation       Best: 0.60 (Val F1: 0.641)\n",
      "  Other                                    Best: 0.80 (Val F1: 0.566)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Get raw probabilities (sigmoids) from the val set to find the best cut-off points\n",
    "model.eval()\n",
    "val_probs = []\n",
    "val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        # Move inputs to GPU\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items() if k in ['input_ids', 'attention_mask', 'labels']}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        # Apply sigmoid to get 0-1 probabilities\n",
    "        probs = torch.sigmoid(outputs.logits)\n",
    "        \n",
    "        val_probs.append(probs.cpu().numpy())\n",
    "        val_labels.append(batch['labels'].cpu().numpy())\n",
    "        \n",
    "        # for sanity, let's inspect the raw sigmoids once\n",
    "        if i % 3000 == 0:\n",
    "            print(probs)\n",
    "\n",
    "val_probs = np.vstack(val_probs)\n",
    "val_labels = np.vstack(val_labels)\n",
    "\n",
    "# Find the optimal threshold for EACH class\n",
    "# We test thresholds from 0.1 to 0.9 and pick the one that maximizes F1 for that specific class\n",
    "best_thresholds = np.array([0.5] * 15) # Start with default\n",
    "n_classes = 15\n",
    "\n",
    "print(\"\\nFinding optimal thresholds per class...\")\n",
    "for i in range(n_classes):\n",
    "    best_score = 0\n",
    "    best_thresh = 0.5\n",
    "    \n",
    "    # Get just the column for this class\n",
    "    y_true = val_labels[:, i]\n",
    "    y_score = val_probs[:, i]\n",
    "    \n",
    "    # Grid search thresholds\n",
    "    for thresh in np.arange(0.1, 0.95, 0.05): # test over increments of 0.05\n",
    "        y_pred = (y_score > thresh).astype(int) # calc pred using this new value\n",
    "        score = f1_score(y_true, y_pred) # calc total f1 score\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thresh = thresh\n",
    "            \n",
    "    best_thresholds[i] = best_thresh # record and save\n",
    "    class_name = official_labels[i]\n",
    "    print(f\"  {class_name:<40} Best: {best_thresh:.2f} (Val F1: {best_score:.3f})\")\n",
    "\n",
    "# below is our raw sigmoid tensor for one batch + results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf89da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying optimal thresholds to Test Set...\n",
      "\n",
      " Optimized performance report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rhrou\\miniconda3\\envs\\framing_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# These seem reasonable, and are worth a shot in implementing, huge variance between classes\n",
    "\n",
    "# Apply these optimized thresholds to the TEST set\n",
    "print(\"\\nApplying optimal thresholds to Test Set...\")\n",
    "test_probs = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items() if k in ['input_ids', 'attention_mask', 'labels']}\n",
    "        outputs = model(**batch)\n",
    "        probs = torch.sigmoid(outputs.logits)\n",
    "        test_probs.append(probs.cpu().numpy())\n",
    "        test_labels.append(batch['labels'].cpu().numpy())\n",
    "\n",
    "test_probs = np.vstack(test_probs)\n",
    "test_labels = np.vstack(test_labels)\n",
    "\n",
    "# Apply specific threshold for each column\n",
    "test_preds_optimized = np.zeros_like(test_probs)\n",
    "for i in range(n_classes):\n",
    "    test_preds_optimized[:, i] = (test_probs[:, i] > best_thresholds[i]).astype(int)\n",
    "\n",
    "# 4. Final Report\n",
    "print(\"\\n Optimized performance report\")\n",
    "report = classification_report(test_labels, test_preds_optimized, target_names=official_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce3946f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Political</th>\n",
       "      <td>0.883311</td>\n",
       "      <td>0.947027</td>\n",
       "      <td>0.914060</td>\n",
       "      <td>3549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legality, constitutionality and jurisprudence</th>\n",
       "      <td>0.823736</td>\n",
       "      <td>0.909326</td>\n",
       "      <td>0.864417</td>\n",
       "      <td>3099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairness and equality</th>\n",
       "      <td>0.738207</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.789069</td>\n",
       "      <td>2419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.717809</td>\n",
       "      <td>0.812183</td>\n",
       "      <td>0.760816</td>\n",
       "      <td>23262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime and punishment</th>\n",
       "      <td>0.746572</td>\n",
       "      <td>0.771750</td>\n",
       "      <td>0.758952</td>\n",
       "      <td>2046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.711012</td>\n",
       "      <td>0.812183</td>\n",
       "      <td>0.758237</td>\n",
       "      <td>23262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security and defense</th>\n",
       "      <td>0.729595</td>\n",
       "      <td>0.787136</td>\n",
       "      <td>0.757274</td>\n",
       "      <td>1306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.726548</td>\n",
       "      <td>0.830207</td>\n",
       "      <td>0.754633</td>\n",
       "      <td>23262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy prescription and evaluation</th>\n",
       "      <td>0.689866</td>\n",
       "      <td>0.830069</td>\n",
       "      <td>0.753501</td>\n",
       "      <td>2042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public opinion</th>\n",
       "      <td>0.637718</td>\n",
       "      <td>0.829395</td>\n",
       "      <td>0.721035</td>\n",
       "      <td>2116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economic</th>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.765073</td>\n",
       "      <td>0.715258</td>\n",
       "      <td>1443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>External regulation and reputation</th>\n",
       "      <td>0.669154</td>\n",
       "      <td>0.718291</td>\n",
       "      <td>0.692853</td>\n",
       "      <td>1498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.644847</td>\n",
       "      <td>0.736877</td>\n",
       "      <td>0.686029</td>\n",
       "      <td>23262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morality</th>\n",
       "      <td>0.670365</td>\n",
       "      <td>0.678973</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cultural identity</th>\n",
       "      <td>0.596690</td>\n",
       "      <td>0.715031</td>\n",
       "      <td>0.650522</td>\n",
       "      <td>958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quality of life</th>\n",
       "      <td>0.491947</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>0.579310</td>\n",
       "      <td>954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health and safety</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.569388</td>\n",
       "      <td>0.569969</td>\n",
       "      <td>490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capacity and resources</th>\n",
       "      <td>0.408517</td>\n",
       "      <td>0.582022</td>\n",
       "      <td>0.480074</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.344937</td>\n",
       "      <td>0.397810</td>\n",
       "      <td>0.369492</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               precision    recall  f1-score  \\\n",
       "Political                                       0.883311  0.947027  0.914060   \n",
       "Legality, constitutionality and jurisprudence   0.823736  0.909326  0.864417   \n",
       "Fairness and equality                           0.738207  0.847458  0.789069   \n",
       "weighted avg                                    0.717809  0.812183  0.760816   \n",
       "Crime and punishment                            0.746572  0.771750  0.758952   \n",
       "micro avg                                       0.711012  0.812183  0.758237   \n",
       "Security and defense                            0.729595  0.787136  0.757274   \n",
       "samples avg                                     0.726548  0.830207  0.754633   \n",
       "Policy prescription and evaluation              0.689866  0.830069  0.753501   \n",
       "Public opinion                                  0.637718  0.829395  0.721035   \n",
       "Economic                                        0.671533  0.765073  0.715258   \n",
       "External regulation and reputation              0.669154  0.718291  0.692853   \n",
       "macro avg                                       0.644847  0.736877  0.686029   \n",
       "Morality                                        0.670365  0.678973  0.674641   \n",
       "Cultural identity                               0.596690  0.715031  0.650522   \n",
       "Quality of life                                 0.491947  0.704403  0.579310   \n",
       "Health and safety                               0.570552  0.569388  0.569969   \n",
       "Capacity and resources                          0.408517  0.582022  0.480074   \n",
       "Other                                           0.344937  0.397810  0.369492   \n",
       "\n",
       "                                               support  \n",
       "Political                                       3549.0  \n",
       "Legality, constitutionality and jurisprudence   3099.0  \n",
       "Fairness and equality                           2419.0  \n",
       "weighted avg                                   23262.0  \n",
       "Crime and punishment                            2046.0  \n",
       "micro avg                                      23262.0  \n",
       "Security and defense                            1306.0  \n",
       "samples avg                                    23262.0  \n",
       "Policy prescription and evaluation              2042.0  \n",
       "Public opinion                                  2116.0  \n",
       "Economic                                        1443.0  \n",
       "External regulation and reputation              1498.0  \n",
       "macro avg                                      23262.0  \n",
       "Morality                                         623.0  \n",
       "Cultural identity                                958.0  \n",
       "Quality of life                                  954.0  \n",
       "Health and safety                                490.0  \n",
       "Capacity and resources                           445.0  \n",
       "Other                                            274.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(report).transpose().sort_values(by=\"f1-score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6903e",
   "metadata": {},
   "source": [
    "\n",
    "#### Some notes from run 1\n",
    "Now we've improved model performance a reasonable amount just in post-train evaluation.\n",
    "Largest gains came for the Macro F1 (per class) up to 0.706 from 0.695. And for Micro F1 (Global) from 0.720 to 0.731. \n",
    "Policy perscription and Cultural identity F1 increases by 3.3% and 2.2% respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "147aafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best thresholds array\n",
    "import json # json always best for dicts\n",
    "import os\n",
    "\n",
    "#  Create a dictionary mapping class names to your optimized thresholds\n",
    "# 'official_labels' is your list of 15 strings\n",
    "# 'best_thresholds' is the numpy array of 15 floats you just calculated\n",
    "threshold_dict = dict(zip(official_labels, best_thresholds))\n",
    "\n",
    "# 2. Save to JSON\n",
    "save_path = \"saved_models/framing_training_runs/class_thresholds_post_train_run_5_bert.json\"\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(threshold_dict, f, indent=4)\n",
    "\n",
    "# --- HOW TO LOAD LATER (For Inference) ---\n",
    "# with open(save_path, 'r') as f:\n",
    "#     loaded_thresholds = json.load(f)\n",
    "# \n",
    "# # Example usage during prediction:\n",
    "# prob = 0.35\n",
    "# if prob > loaded_thresholds[\"Cultural identity\"]:\n",
    "#     print(\"It's a match!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fce2a0",
   "metadata": {},
   "source": [
    "### Architecture notes\n",
    "\n",
    "It's likely that the model could perform better for specific groups of articles, such as s\n",
    "\n",
    "Generating multiple models for different empirical topics would likely improve overall F1-score, and allow the end use-case to have greater accuracy. For instance, allowing the user to choose between a political, exploit the consolidated topics from topic_classifier model:\n",
    "1. allow user to either set the topic from the 19 choices (or just the topics with the largest training data/ best performance from that phase of testing) OR have a two-staged architecture which firstly predicts the topic, then activate an appropriate fine-tuned model that employs learning on just that topic\n",
    "2. Run the specified fine-tuned model OR use the generic model trained across all empirical topics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45168a",
   "metadata": {},
   "source": [
    "### Model training / results storage notes\n",
    "\n",
    "Have to find a better way to accurately store the category-specific and full post optimal classification thresholds F1 scores, as have been recording manually so far"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
