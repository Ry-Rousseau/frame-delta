{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372548ed",
   "metadata": {},
   "source": [
    "## Topic classifier using BERT\n",
    "\n",
    "Development for a practice topic classifier on column (gpt_topic) using DistillBERT with head and tail tokens long-doc policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73c81bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import transformers\n",
    "load_dotenv()  # looks for .env in current directory or parent\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f175efb",
   "metadata": {},
   "source": [
    "#### Sample a dataset via query + tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd45e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Column(name='gpt_topic', type_code=25), Column(name='maintext', type_code=25))\n"
     ]
    }
   ],
   "source": [
    "# Connect to server \n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    dbname=os.getenv(\"DB_NAME\"),\n",
    "    user=os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\")\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Do our join in database\n",
    "cur.execute(f\"\"\"\n",
    "           SELECT gpt_topic,\n",
    "           b.maintext\n",
    "           FROM mm_framing_full a\n",
    "           JOIN newsarticles b ON a.url = b.url\n",
    "           ORDER BY RANDOM()\n",
    "            LIMIT 30000\n",
    "            \"\"\")\n",
    "\n",
    "result= cur.fetchall()\n",
    "\n",
    "print(cur.description)\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "df = pd.DataFrame(result, columns=[\"gpt_topic\", \"article_text\"])\n",
    "df.head()\n",
    "\n",
    "del result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909162cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 30000\n",
      "Filtered rows: 29538\n",
      "Topics removed: 76\n"
     ]
    }
   ],
   "source": [
    "## ESSENTIAL DATA FILTERING\n",
    "# REMOVE rows that have less than 10 observations for the topic\n",
    "\n",
    "counts = df.groupby('gpt_topic')['gpt_topic'].transform('count')\n",
    "\n",
    "# 2. Filter the DataFrame\n",
    "df_filtered = df[counts >= 10].copy()\n",
    "\n",
    "# 3. Check the result\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"Filtered rows: {len(df_filtered)}\")\n",
    "print(f\"Topics removed: {df['gpt_topic'].nunique() - df_filtered['gpt_topic'].nunique()}\")\n",
    "df = df_filtered\n",
    "\n",
    "del df_filtered, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e7a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 1005, 1049, 1037, 2502, 2630, 2300, 10199, 2239, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertTokenizer\n",
    "\n",
    "# choosing a base tokenizer model, this won't \n",
    "model = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model)\n",
    "\n",
    "test_text = \"I'm a big blue watermelon\"\n",
    "\n",
    "encoded_input = tokenizer(test_text)\n",
    "print(encoded_input)\n",
    "\n",
    "# generally want to keep the tokenizations in a separate variable rather than adding them back to the dataframe (for efficiency, taking advantage of the batching features of the huggingface tokenizer)\n",
    "\n",
    "encodings = tokenizer(df['article_text'].tolist(),                      # we opt to dynamically do padding later with head/tail strategy\n",
    "                      # hence we also don't need truncation here\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e5669eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['gpt_topic'].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22659164",
   "metadata": {},
   "source": [
    "### Implement head/tail cutting strategy to mesh into 512 token limit\n",
    "\n",
    "Go for a balance of head - 320, and tail - 190 to balance beginning and ending article context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a163036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531.8111246529894\n",
      "13478\n",
      "7647\n",
      "29538\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "\n",
    "# Firstly, how many are we gonna change\n",
    "lengths = [len(encoding) for encoding in encodings['input_ids']]\n",
    "print(stat.mean(lengths))\n",
    "\n",
    "exceed_count = len(list(filter(lambda l: l > 512, lengths)))\n",
    "print(exceed_count)\n",
    "\n",
    "# How many are super short? out of curiosity\n",
    "short_count = len(list(filter(lambda l: l < 150, lengths)))\n",
    "print(short_count)\n",
    "\n",
    "print(len(encodings['input_ids']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45cc680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1037, 2304] 512\n",
      "[101, 3481, 23520] 128\n",
      "[101, 2009, 1521] 512\n",
      "[101, 1037, 3066] 19\n",
      "[101, 3533, 7226] 512\n",
      "[101, 2225, 29466] 512\n",
      "[101, 9553, 1010] 240\n",
      "[101, 1037, 2610] 452\n",
      "[101, 1037, 12058] 512\n",
      "[101, 8645, 18981] 39\n"
     ]
    }
   ],
   "source": [
    "# Code to set the unique head and tail of the articles\n",
    "head_len = 320\n",
    "tail_len = 190\n",
    "content_len = head_len + tail_len          \n",
    "max_len = content_len + 2  # [CLS] + [SEP]      \n",
    "\n",
    "cls_id = tokenizer.cls_token_id\n",
    "sep_id = tokenizer.sep_token_id\n",
    "pad_id = tokenizer.pad_token_id\n",
    "\n",
    "for i, ids in enumerate(encodings[\"input_ids\"]):\n",
    "    # ClS and Sep Id's are present in tokenized values, so do this\n",
    "    if len(ids) >= 2 and ids[0] == cls_id and ids[-1] == sep_id:\n",
    "        ids = ids[1:-1]\n",
    "\n",
    "    # Head+tail on the content tokens\n",
    "    if len(ids) > content_len:\n",
    "        head = ids[:head_len]\n",
    "        tail = ids[-tail_len:]\n",
    "        ids = head + tail\n",
    "\n",
    "    # Add specials back\n",
    "    ids = [cls_id] + ids + [sep_id]\n",
    "\n",
    "    # Build attention mask (1 for real tokens)\n",
    "    mask = [1] * len(ids)\n",
    "\n",
    "    # Pad (or truncate)\n",
    "    if len(ids) < max_len:\n",
    "        pad_n = max_len - len(ids)\n",
    "        ids = ids + [pad_id] * pad_n\n",
    "        mask = mask + [0] * pad_n\n",
    "    else:\n",
    "        ids = ids[:max_len]\n",
    "        mask = mask[:max_len]\n",
    "\n",
    "    # Write back\n",
    "    encodings[\"input_ids\"][i] = ids\n",
    "    encodings[\"attention_mask\"][i] = mask\n",
    "\n",
    "# quick sanity check\n",
    "for ids, mask in zip(encodings[\"input_ids\"][:10], encodings[\"attention_mask\"][:10]):\n",
    "    assert len(ids) == 512 and len(mask) == 512\n",
    "    print(ids[:3], sum(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765db7e2",
   "metadata": {},
   "source": [
    "### PyTorch Dataset Creation\n",
    "\n",
    "Using `torch.utils.data.Dataset` and `torch.utils.data.DataLoader`\n",
    "\n",
    "[Pytorch data tutorial](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74d2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first have to convert our label in the df into a categorical so it processes correctly\n",
    "df['topic_cat'] = df['gpt_topic'].astype('category')\n",
    "label_ids = df['topic_cat'].cat.codes\n",
    "id_to_label = list(df['topic_cat'].cat.categories)\n",
    "label_to_id = {label: i for i, label in enumerate(id_to_label)}\n",
    "\n",
    "# so label_ids is our list of integer representations of our original topic labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87b71ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine distribution of value counts of labels\n",
    "df['topic_cat'].value_counts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Calculate counts and take the top 20\n",
    "top_topics = df['topic_cat'].value_counts().head(20)\n",
    "\n",
    "# 2. Create a horizontal bar chart\n",
    "# We sort_values() at the end so the highest count is at the top of the chart\n",
    "top_topics.sort_values().plot(kind='barh', figsize=(10, 8), color='teal')\n",
    "\n",
    "plt.title('Most frequent 20 categories') # \"The 20 most frequent categories\"\n",
    "plt.xlabel('Number of articles') # \"Number of articles\"\n",
    "plt.ylabel('Topic')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('plots/topic_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52dffb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Get the 20 least frequent categories\n",
    "# .value_counts() sorts by descending order by default, so .tail(20) gets the smallest\n",
    "bottom_topics = df['topic_cat'].value_counts().tail(20)\n",
    "\n",
    "# 2. Create the horizontal bar chart\n",
    "# We sort them so the smallest bars are at the top for better readability\n",
    "bottom_topics.sort_values(ascending=True).plot(kind='barh', figsize=(10, 8), color='salmon')\n",
    "\n",
    "plt.title('Least Frequent categories') # The 20 least frequent categories\n",
    "plt.xlabel('Number of articles')\n",
    "plt.ylabel('Topic')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('plots/least_frequent_topics.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3aea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the below to record the raw text, but filter this out in batch processing\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NewsArticleDataset(Dataset):\n",
    "    def __init__(self, encodings, label_ids: pd.Series):\n",
    "        self.input_ids = encodings['input_ids']\n",
    "        self.attention_mask = encodings['attention_mask']\n",
    "        self.labels = label_ids.to_list() # convert to list for indexing robustness  \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        # for transformer style training, generally return a dict with keys that match what your model expects\n",
    "        dict_to_return = {'input_ids': torch.tensor(self.input_ids[idx], dtype = torch.long), # convert to tensors, 64-bit integer (long) dtype \n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype = torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype =torch.long)}\n",
    "        return dict_to_return\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e02ee8",
   "metadata": {},
   "source": [
    "### Creating the test/train/val split\n",
    "\n",
    "Since we have so many unique classes (100+) it seems best to stratify our data split to balance class distributions.\n",
    "\n",
    "Can use `sklearn.model_selection.train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cab782d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23626 2953 2954\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# integer-coded labels aligned with encodings order\n",
    "labels = np.array(label_ids, dtype=np.int64) # numpy array\n",
    "\n",
    "N = len(labels)\n",
    "idx = np.arange(N)\n",
    "\n",
    "# 80/10/10 split (train/val/test), stratified\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    idx,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=labels # as array\n",
    ")\n",
    "\n",
    "# Run it again on the temp test set to get the val set\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx,\n",
    "    test_size=0.50,                    # half of 20% -> 10% val, 10% test\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=labels[temp_idx]\n",
    ")\n",
    "\n",
    "# Build ONE dataset, then slice with Subset\n",
    "full_df = NewsArticleDataset(encodings, label_ids)  # or NewsArticleDataset(encodings, labels)\n",
    "train = Subset(full_df, train_idx) # basically does what it says on the tin\n",
    "val   = Subset(full_df, val_idx)\n",
    "test  = Subset(full_df, test_idx)\n",
    "\n",
    "print(len(train), len(val), len(test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e96e46",
   "metadata": {},
   "source": [
    "### Creating the data loader\n",
    "\n",
    "Knobs start appearing to be tweaked here, large number of options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b36d80cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2508,  1998,  7673, 13675, 26607,  2100,  1010,  1996,  3008,\n",
       "          1997,  1996,  4345,  2152,  2082,  1010,  2020,  7331,  2006,  9857,\n",
       "          1010,  2258,  1023,  1010,  2044,  2027,  2020,  2169,  7979,  1997,\n",
       "         26097, 16042, 17298, 13900,  2121,  1012,  1996,  3008,  1005,  2365,\n",
       "          2001,  7331,  2000,  2166,  1999,  3827,  2197,  2095,  2005,  1996,\n",
       "          5008,  2008,  2730,  2176,  2493,  1012,  1996, 13675, 26607,  7274,\n",
       "          2020,  5496,  1997,  2025,  2893,  2037,  2365,  2393,  1998,  2025,\n",
       "          7919, 12329,  1037,  3282,  2008,  2001,  2109,  1999,  1996,  5008,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(10)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check the get item method on data set class\n",
    "full_df.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b1ffc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data loader \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train, \n",
    "                          batch_size = batch_size, # number of articles to be fed into the model at once\n",
    "                          num_workers=0, # increase this later on\n",
    "                          shuffle = True, \n",
    "                          pin_memory= True)\n",
    "val_loader = DataLoader(val, \n",
    "                          batch_size = batch_size, # number of articles to be fed into the model at once\n",
    "                          shuffle = False, # false so eval is deterministic and reproducible\n",
    "                          pin_memory= True)\n",
    "test_loader = DataLoader(test, \n",
    "                          batch_size = batch_size, # number of articles to be fed into the model at once\n",
    "                          shuffle = False,  # false, as above\n",
    "                          pin_memory= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c62b654",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Another sanity check, confirming shapes match expectations\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# grab a batch using iterator next()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m batch[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m].shape, batch[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m].shape, batch[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].shape\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 32 (batch_size) X (number of tokens) = like a spreadsheet with all our tokens and 32 examples\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:759\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    757\u001b[39m data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m     data = \u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pin_memory_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:75\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections.abc.MutableMapping):\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# The sequence type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new sequence.\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the sequence type is mutable.\u001b[39;00m\n\u001b[32m     73\u001b[39m     clone = copy.copy(data)\n\u001b[32m     74\u001b[39m     clone.update(\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:75\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections.abc.MutableMapping):\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# The sequence type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new sequence.\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the sequence type is mutable.\u001b[39;00m\n\u001b[32m     73\u001b[39m     clone = copy.copy(data)\n\u001b[32m     74\u001b[39m     clone.update(\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         {k: \u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, sample \u001b[38;5;129;01min\u001b[39;00m data.items()}\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:64\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpin_memory\u001b[39m(data, device=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch.Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[32m     66\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Another sanity check, confirming shapes match expectations\n",
    "\n",
    "# grab a batch using iterator next()\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "batch['input_ids'].shape, batch['attention_mask'].shape, batch['labels'].shape\n",
    "\n",
    "# 32 (batch_size) X (number of tokens) = like a spreadsheet with all our tokens and 32 examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54b8f842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.int64, torch.int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also quickly check dtypes\n",
    "batch[\"input_ids\"].dtype, batch[\"attention_mask\"].dtype, batch[\"labels\"].dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3cc0a",
   "metadata": {},
   "source": [
    "### Load Model and set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44923851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=67, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To avoid writing a head we can load it manually\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=67)\n",
    "model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6febedbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.239929676055908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(4.2399, device='cuda:0'), logits=tensor([[-0.0689,  0.1553,  0.0723,  ...,  0.1338,  0.0356, -0.0094],\n",
       "        [-0.1018,  0.1129,  0.1078,  ...,  0.0980,  0.0953, -0.0158],\n",
       "        [-0.1129,  0.1195,  0.0941,  ...,  0.1297,  0.0490, -0.0610],\n",
       "        ...,\n",
       "        [-0.1098,  0.1301,  0.1045,  ...,  0.1317,  0.0568,  0.0060],\n",
       "        [-0.1136,  0.1345,  0.1248,  ...,  0.1211,  0.0228, -0.0097],\n",
       "        [-0.1195,  0.1322,  0.0503,  ...,  0.0851,  0.0606, -0.0313]],\n",
       "       device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run through a mini one-example batch of what the model is actually doing and examine outputs, loss, logits, \n",
    "\n",
    "import torch\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad(): # do no grad so we don't build up memory on the GPU accidently\n",
    "    outputs = model(\n",
    "        input_ids=batch[\"input_ids\"],\n",
    "        attention_mask=batch[\"attention_mask\"],\n",
    "        labels=batch[\"labels\"],\n",
    "    )\n",
    "    loss = outputs.loss\n",
    "    logits = outputs.logits\n",
    "\n",
    "print(loss.item())\n",
    "\n",
    "logits = outputs.logits  # shape: (batch_size, num_labels)\n",
    "\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4996414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing memory\n",
    "del outputs, logits, loss, batch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53dc9969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      | 271177 KiB |    825 MiB |   5738 MiB |   5474 MiB |\\n|       from large pool | 270720 KiB |    824 MiB |   5698 MiB |   5434 MiB |\\n|       from small pool |    457 KiB |      1 MiB |     40 MiB |     40 MiB |\\n|---------------------------------------------------------------------------|\\n| Active memory         | 271177 KiB |    825 MiB |   5738 MiB |   5474 MiB |\\n|       from large pool | 270720 KiB |    824 MiB |   5698 MiB |   5434 MiB |\\n|       from small pool |    457 KiB |      1 MiB |     40 MiB |     40 MiB |\\n|---------------------------------------------------------------------------|\\n| Requested memory      | 270070 KiB |    823 MiB |   5737 MiB |   5473 MiB |\\n|       from large pool | 269614 KiB |    823 MiB |   5696 MiB |   5433 MiB |\\n|       from small pool |    456 KiB |      1 MiB |     40 MiB |     40 MiB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   | 299008 KiB |    996 MiB |    996 MiB | 720896 KiB |\\n|       from large pool | 296960 KiB |    994 MiB |    994 MiB | 720896 KiB |\\n|       from small pool |   2048 KiB |      2 MiB |      2 MiB |      0 KiB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  27830 KiB | 175039 KiB |    941 MiB |    914 MiB |\\n|       from large pool |  26240 KiB | 173696 KiB |    899 MiB |    874 MiB |\\n|       from small pool |   1590 KiB |   2045 KiB |     42 MiB |     40 MiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     108    |     118    |     310    |     202    |\\n|       from large pool |      40    |      48    |     120    |      80    |\\n|       from small pool |      68    |      78    |     190    |     122    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     108    |     118    |     310    |     202    |\\n|       from large pool |      40    |      48    |     120    |      80    |\\n|       from small pool |      68    |      78    |     190    |     122    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      12    |      21    |      21    |       9    |\\n|       from large pool |      11    |      20    |      20    |       9    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      12    |      14    |      54    |      42    |\\n|       from large pool |       9    |      11    |      18    |       9    |\\n|       from small pool |       3    |       5    |      36    |      33    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking memory usage by cuda\n",
    "torch.cuda.memory_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b4f56",
   "metadata": {},
   "source": [
    "### Setting Loss and Optimizer before training\n",
    "\n",
    "Define optimizer as AdamW (a fine choice for now)\n",
    "Set an LR scheduler or define manually, setting a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10cf17bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer  and LR\n",
    "optimizer = torch.optim.AdamW(lr=2e-5, # for transformers, we want a low learning rate, even lower than 0.001\n",
    "                              weight_decay= 0.01, # this basically is L2 regularization applied through, penalizeing large weight, encouragin params to stay smaller, can help reduce overfitting and improve generalization\n",
    "                             params=model.parameters()) # tell the optimizer what parameters to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9534f38d",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We use the same structure as in a linear regression torch training loop but we instead, with transformers, train over batches from the DataLoader, moving each batch to the GPU, and the model can compute loss internally when you pass \"labels\" object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0b7c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a clean state, hard reset the GPU state\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07b47b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "\n",
    "#     running_loss = 0.0\n",
    "\n",
    "#     for batch in train_loader:\n",
    "#         # 1) move batch to GPU\n",
    "#         batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "\n",
    "#         # 2) forward pass \n",
    "#         outputs = model(\n",
    "#             input_ids=batch[\"input_ids\"],\n",
    "#             attention_mask=batch[\"attention_mask\"],\n",
    "#             labels=batch[\"labels\"] # had a rough comma here b4\n",
    "#         )\n",
    "\n",
    "#         loss = outputs.loss # default loss from the HF auto model, likely cross entropy\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#         # 3) zero grad\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # 4) backward\n",
    "#         loss.backward()\n",
    "\n",
    "#         # 5) step\n",
    "#         optimizer.step()\n",
    "\n",
    "#     # ---- validation ----\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in val_loader:\n",
    "#             batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "#             outputs = model(\n",
    "#                 input_ids=batch[\"input_ids\"],\n",
    "#                 attention_mask=batch[\"attention_mask\"],\n",
    "#                 labels=batch[\"labels\"],\n",
    "#             )\n",
    "#             val_loss += outputs.loss.item()\n",
    "\n",
    "#             logits = outputs.logits\n",
    "#             preds = logits.argmax(dim=-1)\n",
    "#             correct += (preds == batch[\"labels\"]).sum().item()\n",
    "#             total += batch[\"labels\"].size(0)\n",
    "\n",
    "#     print(\n",
    "#         f\"Epoch {epoch} | train_loss={running_loss/len(train_loader):.4f} \"\n",
    "#         f\"| val_loss={val_loss/len(val_loader):.4f} | val_acc={correct/total:.4f}\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4daed5",
   "metadata": {},
   "source": [
    "### Evaluating and re-adjusting model approach\n",
    "\n",
    "Seems like training is failing silently given that validation accuracy maxes out at epoch 0, a major risk specified in karpathy's recipe for training NNs. I should assume either overfitting or a pipeline/data issue until proven otherwise. To do this, we should build some paranoia checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27483cc",
   "metadata": {},
   "source": [
    "#### Paranoia check 1: \"set up the full skeleton + get dumb baselines\"\n",
    "Find out\n",
    "* Majority-class accuracy\n",
    "* Random baseline\n",
    "* \"input-independent baseline\"\n",
    "\n",
    "Having re-checked the code, I don't believe it is a mis-labelling issue- label_ids match up with encodings via index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3be3df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt_topic</th>\n",
       "      <th>article_text</th>\n",
       "      <th>topic_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29533</td>\n",
       "      <td>29533</td>\n",
       "      <td>29533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>65</td>\n",
       "      <td>28937</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Politics</td>\n",
       "      <td>BALTIMORE-- After a cloudy and mild Friday acr...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4384</td>\n",
       "      <td>18</td>\n",
       "      <td>4384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gpt_topic                                       article_text topic_cat\n",
       "count      29533                                              29533     29533\n",
       "unique        65                                              28937        65\n",
       "top     Politics  BALTIMORE-- After a cloudy and mild Friday acr...  Politics\n",
       "freq        4384                                                 18      4384"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "# we correctly specified 67 unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a840c586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEWYou can now listen to Fox News articles!\n",
      "A massive car crash involving 72 vehicles in Farmersville, Illinois, Monday morning left at least six people dead and 37 people injured, police said.\n",
      "According to Illinois State Police, the surviving victims  whose ages ranged between 2 years and 80 years old  were transported to local hospitals with various injuries. Some of whom are said to be in critical condition.\n",
      "\"At 10:55 a.m. there was a crash on northbound Interstate 55 at Milepost 76. At the same time, there were numerous crashes on southbound Interstate 55 at Milepost 76. The crashes occurred within a two-mile stretch  from roughly Milepost 76 to Milepost 78,\" the police statement read.\n",
      "It continued: \"Reports show there are six fatalities, all occurring in the northbound lanes. At this time, one decedent has been identified as 88-year-old Shirley Harper of Franklin, WI. The Montgomery County Corners Office is working diligently to identify the other five individuals and notify their families.\"\n",
      "ILLINOIS DUST STORM RESPONSIBLE FOR MULTIPLE FATALITIES AFTER CARS PILE UP IN WRECKAGE\n",
      "The lanes remained closed through the afternoon and into Tuesday morning.\n",
      "\"Once the interstate is clear of all vehicles, the Illinois Department of Transportation will have to inspect the roadway before it is re-opened,\" the police said.\n",
      "At least two of the tractor-trailers involved caught fire.\n",
      "State Police Maj. Ryan Starrick said the crash was caused by a windstorm that kicked up clouds of dust.\n",
      "\"The cause of the crashes is due to excessive winds blowing dirt from farm fields across the highway, leading to zero visibility,\" Starrick said.\n",
      "TORNADOES STRIKE VIRGINIA AND FLORIDA, FLOODING IN OTHER STATES\n",
      "Kevin Schott, the director of emergency services in Montgomery County, described the crash as a \"very difficult scene\" and said it was \"very hard to train for.\"\n",
      "\"We had to search every vehicle, whether they were involved in the accident or just pulled over, to check for injuries,\" Schott said. He also said those involved were visibly and understandably upset.\n",
      "Illinois Gov. J.B. Pritzker similarly described the scene as \"horrific.\"\n",
      "\"I am closely monitoring the horrific situation at the Macoupin and Sangamon County line on I-55. My team is in constant communication with the Illinois State Police, Department of Transportation, and Emergency Management Agency to ensure the safety of motorists as they navigate dangerous conditions,\" Pritzker wrote in a statement.\n",
      "CLICK HERE TO GET THE FOX NEWS APP\n",
      "He added: \"On the ground, our first responders and emergency management teams are working diligently to clear the road, provide medical care to those in need, and collaborate with local officials to provide support to everyone affected by this tragic accident.\"\n",
      "Wind gusts at the time of the crash were between 35 mph and 45 mph.\n",
      "Crime\n",
      "The California Governor's Office of Emergency Services advised residents to inspect their trees after the recent rain storms. Nicole Comstock reports.\n",
      "Environment\n",
      "James and Jennifer Crumbley, the parents of the Oxford High School, were sentenced on Tuesday, April 9, after they were each convicted of involuntary manslaughter. The parents' son was sentenced to life in prison last year for the shooting that killed four students. The Crumbleys were accused of not getting their son help and not properly securing a gun that was used in the shooting.\n",
      "Legal\n",
      "AMY GOODMAN: As Memorial Day weekend begins here in the United States, we end todays show looking back at the largely forgotten 1937 Memorial Day Massacre, when police in Chicago shot at and gassed a peaceful gathering of striking steelworkers and their supporters, killing 10 people, most of them shot in the back. It was a time like today, when unions were growing stronger. The workers were on strike against Republic Steel. The police attacked them with weapons supplied by the company.\n",
      "The tragic story is told in a new PBS documentary, Memorial Day Massacre: Workers Die, Film Buried. It based on book with oral histories of eyewitnesses of the attack. The film begins with the great radio broadcaster Studs Terkel.\n",
      "STUDS TERKEL: This is 1937, and the labor battles are going on. The CIO is being organized. And the steelworkers and the packing, theyre all being organized. And the Big Steel, the big steel companies, finally agreed. They recognized the union. But theres one company in Chicago, Republic Steel, Tom Girdler: I will not recognize the union.\n",
      "And so there was a strike. Memorial Day 1937. And there was a picnic. Strikers and their wives and kids are on the grounds of Republic Steel in South Chicago. Someone threw a stone, and cops were there at the behest of Girdler. And they shot down 10 people, killed them, in the back.\n",
      "JOSH CHARLES: In the days that followed, newspapers from coast to coast portrayed the incident as a riot provoked by a dangerous mob, which left police no choice but to open fire, with 10 dead within days. However, the key piece of evidence, the only film of the tragedy, remained buried. Paramount News created, then suppressed, a newsreel airing the footage. When the hidden footage was finally screened, the shocking images drew national attention, with vital lessons for today.\n",
      "AMY GOODMAN: Thats the opening to the new documentary, Memorial Day Massacre: Workers Die, Film Buried. This is another clip, when an eyewitness describes how the police attack unfolded. We hear from reporter Harold Rossman and Mollie West, who was a teenager when she attended the Memorial Day gathering in support of the striking workers.\n",
      "MOLLIE WEST: We just walked. And people were talking and holding hands, and the children were being carried by their fathers on their shoulders. And everybody was laughing, and it was a joyous thing. And as we came closer to the mill, the walking slowed a bit. It seemed like the entire police force of the city of Chicago was out there. But that didnt deter. We were still going to go over to the mill and just conduct a peaceful mass picket line.\n",
      "HAROLD ROSSMAN: I could see a few objects through the air. I could see some things being thrown. Not much. It wasnt a lot of stuff, maybe a couple of rocks. There was a dry, crackling kind of a noise. It took me a moment to figure out what it was, and I realized it was gunfire. And by that time, the people were falling. And they were turning and trying to run, and the gunfire continued. It was clear that a whole number of these people had been shot in the back. They were trying to flee, and they were still being fired at.\n",
      "MOLLIE WEST: And then a whole number of people were piled up on top of me, and I could barely breathe. Also, there was tear gas. People finally began to get off, get on their feet. And when I finally stood up, and I  total bewilderment. I looked around, and I saw a battlefield.\n",
      "AMY GOODMAN: The new PBS documentary, Memorial Day Massacre: Workers Die, Film Buried, which just aired on PBS, is now online. Its the latest project from longtime author and journalist Greg Mitchell, whos written 12 books and made many films about U.S. politics and history.\n",
      "Greg, welcome back to Democracy Now! This is a devastating documentary about a story very few people today know, what happened 86 years ago in Chicago. Take it from where we have just heard these eyewitness descriptions. How did this happen?\n",
      "GREG MITCHELL: OK. Well, Im happy to be here.\n",
      "Yes, the police, in fact, shot 40 people, the vast majority in the back or in the side. Ten would die, within days. And then, they  as the film shows, they waded through the crowd, beating people over the head, sometimes with ax handles provided by Republic Steel. And so, there were another 50 people who were injured enough to be hospitalized. And then, again, as the film shows, the injured, instead of getting any medical treatment, were actually arrested and shoved into paddy wagons and taken to jail or taken to distant hospitals.\n",
      "And this is all on the Paramount News footage, which was suppressed. So, we know the step-by-step things that happened. And you can watch \n",
      "AMY GOODMAN: Greg, your film is so good \n",
      "GREG MITCHELL:  almost all the Paramount footage.\n",
      "AMY GOODMAN: Greg, your film is so good, I want to go back to another clip from Memorial Day Massacre.\n",
      "JOSH CHARLES: A disturbing new account of the death of one man emerged. A photo of Earl Handley being carried by police, seemingly for medical attention, had appeared in newspapers earlier. Now the full story came out.\n",
      "Handley, a 37-year-old carpenter, had been shot in the thigh, so a worker tied a tourniquet on his leg to stop the bleeding. The Paramount footage showed him being hauled to a workers car for a quick trip to the hospital. After the camera stopped rolling, however, police yanked him out of the car and carried him to their paddy wagon, as his tourniquet slipped off, and he bled to death.\n",
      "A doctor who treated some of the wounded presented autopsy reports proving that nearly all of the dead had been shot in the back or in the side.\n",
      "AMY GOODMAN: And this is another clip from Memorial Day Massacre about how progressive Senator Robert La Follette subpoenaed the suppressed footage of the attack. This was the first time film was shown as evidence in a Senate hearing.\n",
      "JOSH CHARLES: Senator La Follette announced that the footage would be screened at both regular speed and slow motion. Pointedly, he asked the top Chicago police officials to take a seat to view the film. This was reportedly the first time film footage had ever been introduced as evidence in Congress.\n",
      "The reaction in the hearing room: gasps, some tears, but stony silence from the top police officials. The slow motion revealed a murderous new detail. Much of the press coverage the next day now flipped to blaming the police, although many news outlets now claimed that the camera could indeed lie.\n",
      "NEWSREEL: What happened at South Chicago, Memorial Day, 1937.\n",
      "JOSH CHARLES: Also the following day, Paramount, after burying the first two newsreels, at last released a film based on its footage.\n",
      "NEWSREEL: The following pictures, made before and during the trouble, are shown exactly as they came from the camera, without editing  as presented before the United States Senate committee in Washington.\n",
      "JOSH CHARLES: The newsreel claimed that the footage was not edited, but this was false. Actually, it omitted this crucial footage: the deadly first 15 seconds. So Paramount was still withholding evidence from the public.\n",
      "AMY GOODMAN: Another excerpt of Memorial Day Massacre: Workers Die, Film Buried, the director, Greg Mitchell, with us. I mean, this story of what the public understood happened, with 10 people killed, talk about the role of the media, and the police working with it, whether the camera was shut off, as we saw in that first clip, or Paramount suppressing this, Greg.\n",
      "GREG MITCHELL: Yes. The importance of it was, to me, the mass media, right up to The New York Times, was supporting the police story, that they had no choice but to open fire on this mob. And Paramount had the footage, had the evidence. They created a newsreel, and then they decided not to release it. They created a second newsreel and didnt release that. And it took the being subpoenaed by the La Follette hearing, and the screening on Capitol Hill then forced Paramount to release a third newsreel. And even then, city officials in Chicago, in St. Louis, in Massachusetts banned its showing. So, even in its final form, it was not released in full.\n",
      "AMY GOODMAN: And, Greg, in this last minute, why is Paramount so significant? People might not understand that today. And what is the most important lesson to take of what took place?\n",
      "GREG MITCHELL: Well, you know, as you know, the movies were incredibly popular then. This was before television, so most people got their  certainly their visual news from these newsreels, which were shown in every movie theater at every movie showing.\n",
      "I think the lesson, among other things, is the importance of visual evidence when theres police shootings and police brutality, as we see today. Thats why theres such a focus on releasing bodycams and dashboard cams.\n",
      "Of course, another lesson is, with the great labor activity today, that they stand on the shoulders of the people from the past who sacrificed so much. And thats why Im happy people can watch this film right now on PBS.org, everywhere in the country. And, of course, the book has the oral histories of all eyewitnesses and many of the activists who were wounded.\n",
      "AMY GOODMAN: Greg Mitchell, director of Memorial Day Massacre: Workers Die, Film Buried.\n",
      "And that does it for todays show. Thanks to Tia Potenza Smallwood and Susan Hughes here in Cambridge. Also thanks to Denis Moynihan and Hany Massoud. Im Amy Goodman. Thanks for joining us.\n",
      "Media\n",
      "CHICAGO (CBS) -- Passengers on two planes at O'Hare International Airport had to go back inside the terminal Sunday night after their planes clipped wings on the tarmac.\n",
      "The FAA said All Nippon Airways Flight 11, a Boeing 777, was taxiing for departure around 6:30 p.m. when its left wing hit the stabilizer of Delta Air Lines Flight 2122, a Boeing 717.\n",
      "Officials said the incident happened in an area not under air traffic control.\n",
      "No one on board either plane was injured.\n",
      "The FAA is investigating what caused the planes to collide.\n",
      "Crime\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(df['article_text'][i])\n",
    "    print(df['gpt_topic'][i])\n",
    "    \n",
    "# these labels make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ab8ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 8 most frequent classes proportion\n",
      "66.1090982968205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topic_cat\n",
       "Politics         4384\n",
       "Crime            3889\n",
       "Sports           3737\n",
       "Legal            1794\n",
       "Business         1678\n",
       "Health           1528\n",
       "Entertainment    1292\n",
       "Environment      1222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics = 8\n",
    "print(f\"top {n_topics} most frequent classes proportion\")\n",
    "print(sum(df['topic_cat'].value_counts().iloc[:n_topics])/len(df)*100)\n",
    "\n",
    "df['topic_cat'].value_counts().iloc[:n_topics]\n",
    "\n",
    "# we're likely not experiencing just random baseline or input independent baseline, in fact, in this environment, 67% accuracy isn't bad, but it's concerning why it isn't improving\n",
    "\n",
    "# model may just be learning frequent classes but not the harder more rare classes. This is probably both a data issue and a model (generalization) issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344055e1",
   "metadata": {},
   "source": [
    "### Paranoia check 2: \"overfit one batch\"\n",
    "\n",
    "Taking 16-64 examples and confirm I can drive loss near ~0 and accuracy to 100%. If not, something is wrong in labels, batching or model inputs. Otherwise, pipeline is fine and I'm looking at generalization issues or perhaps too many labels to choose from. \n",
    "\n",
    "Looking for:\n",
    "* training loss goes near zero\n",
    "* training accuracy goes near 100%\n",
    "* predictions become stable and correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c331cf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# reload model as a clean slate\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=67)\n",
    "model.to('cuda')\n",
    "\n",
    "# re-create optimizer \n",
    "optimizer = torch.optim.AdamW(lr=1e-4, # temp increase for this quick test\n",
    "                              weight_decay= 0.01, # this basically is L2 regularization applied through, penalizeing large weight, encouragin params to stay smaller, can help reduce overfitting and improve generalization\n",
    "                             params=model.parameters()) # tell the optimizer what parameters to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f4e6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Freeze randomness and fix one batch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m fixed_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m fixed_batch = {k: v.to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m fixed_batch.items()}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:759\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    757\u001b[39m data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m     data = \u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pin_memory_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:75\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections.abc.MutableMapping):\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# The sequence type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new sequence.\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the sequence type is mutable.\u001b[39;00m\n\u001b[32m     73\u001b[39m     clone = copy.copy(data)\n\u001b[32m     74\u001b[39m     clone.update(\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:75\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections.abc.MutableMapping):\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# The sequence type may have extra properties, so we can't just\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new sequence.\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Create a clone and update it if the sequence type is mutable.\u001b[39;00m\n\u001b[32m     73\u001b[39m     clone = copy.copy(data)\n\u001b[32m     74\u001b[39m     clone.update(\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         {k: \u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, sample \u001b[38;5;129;01min\u001b[39;00m data.items()}\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:64\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpin_memory\u001b[39m(data, device=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch.Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[32m     66\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Freeze randomness and fix one batch\n",
    "fixed_batch = next(iter(train_loader))\n",
    "fixed_batch = {k: v.to(\"cuda\") for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ac4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | 4.165653228759766 | 4.165653228759766 \n",
      "acc: 0.0\n",
      "Epoch 1 | 3.9975008964538574 | 4.0815770626068115 \n",
      "acc: 0.25\n",
      "Epoch 2 | 3.704087734222412 | 3.9557472864786782 \n",
      "acc: 0.5\n",
      "Epoch 3 | 3.3123347759246826 | 3.7948941588401794 \n",
      "acc: 1.0\n",
      "Epoch 4 | 3.1237332820892334 | 3.66066198348999 \n",
      "acc: 1.0\n",
      "Epoch 5 | 2.818068265914917 | 3.520229697227478 \n",
      "acc: 1.0\n",
      "Epoch 6 | 2.467593193054199 | 3.3698530537741527 \n",
      "acc: 1.0\n",
      "Epoch 7 | 2.2516863346099854 | 3.2300822138786316 \n",
      "acc: 1.0\n",
      "Epoch 8 | 2.0234427452087402 | 3.096011161804199 \n",
      "acc: 1.0\n",
      "Epoch 9 | 1.8751627206802368 | 2.973926317691803 \n",
      "acc: 1.0\n",
      "Epoch 10 | 1.6460140943527222 | 2.8532070246609775 \n",
      "acc: 1.0\n",
      "Epoch 50 | 0.01788775809109211 | 0.8543973546109948 \n",
      "acc: 1.0\n",
      "Epoch 100 | 0.005726194009184837 | 0.4371539797532455 \n",
      "acc: 1.0\n",
      "Epoch 150 | 0.0027204686775803566 | 0.29394421906099466 \n",
      "acc: 1.0\n",
      "Epoch 200 | 0.0021151327528059483 | 0.22146429155028857 \n",
      "acc: 1.0\n",
      "Epoch 250 | 0.0015013266820460558 | 0.17766365750374613 \n",
      "acc: 1.0\n",
      "Epoch 300 | 0.0007846929365769029 | 0.14832000865773498 \n",
      "acc: 1.0\n",
      "Epoch 350 | 0.0005792890442535281 | 0.12729568356252408 \n",
      "acc: 1.0\n",
      "Epoch 400 | 0.0004025425878353417 | 0.11149252940214906 \n",
      "acc: 1.0\n",
      "Epoch 450 | 0.0003778712125495076 | 0.09918035168116582 \n",
      "acc: 1.0\n",
      "Epoch 500 | 0.00023290314129553735 | 0.08931152857955083 \n",
      "acc: 1.0\n",
      "Epoch 550 | 0.00012355222133919597 | 0.08122759377940925 \n",
      "acc: 1.0\n",
      "Epoch 600 | 0.00012930236698593944 | 0.07448823256996069 \n",
      "acc: 1.0\n",
      "Epoch 650 | 9.47666703723371e-05 | 0.0687787348659174 \n",
      "acc: 1.0\n",
      "Epoch 700 | 0.000268676521955058 | 0.0638821968871742 \n",
      "acc: 1.0\n",
      "Epoch 750 | 7.089673454174772e-05 | 0.059638054499887024 \n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# train on this batch for many steps\n",
    "\n",
    "# put into training mode\n",
    "#model.train()\n",
    "\n",
    "#running_loss = 0.0\n",
    "\n",
    "# for step in range(800):\n",
    "    \n",
    "#     # forward pass\n",
    "#     outputs = model(\n",
    "#             input_ids=fixed_batch[\"input_ids\"],\n",
    "#             attention_mask=fixed_batch[\"attention_mask\"],\n",
    "#             labels=fixed_batch[\"labels\"]  \n",
    "#     )\n",
    "    \n",
    "#     # find loss\n",
    "#     loss = outputs.loss\n",
    "#     # running loss\n",
    "#     running_loss += loss.item()\n",
    "    \n",
    "#     # backprop + optimizer step\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     loss.backward()\n",
    "    \n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if step % 50 == 0 or step <= 10:\n",
    "#         logits = outputs.logits\n",
    "#         preds = logits.argmax(dim=-1)\n",
    "#         acc = (preds == fixed_batch[\"labels\"]).float().mean().item()\n",
    "#         print(f\"Epoch {step} | {loss.item()} | {running_loss/(step+1)} \")\n",
    "#         print(f\"acc: {acc}\")\n",
    "\n",
    "# # these results looks good, we're overfitting correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efb1dc",
   "metadata": {},
   "source": [
    "Model is training correctly, and reaches 100% accuracy on a sample test batch of size 32 within 4 epochs.\n",
    "So wiring is correct, model can memorize a fixed batch, earlier plateau is not a bug in batching/labels/loss/backprop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db418f44",
   "metadata": {},
   "source": [
    "### Consolidating data distributions / labels \n",
    "\n",
    "67 classes is honestly nuts. Not sure how many of these are truly useful, we should consolidate them down to say ~20 or so labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fb8ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_cat\n",
      "Politics                     4384\n",
      "Crime                        3889\n",
      "Sports                       3737\n",
      "Legal                        1794\n",
      "Business                     1678\n",
      "Health                       1528\n",
      "Entertainment                1292\n",
      "Environment                  1222\n",
      "Culture                       828\n",
      "War                           821\n",
      "Education                     685\n",
      "Weather                       669\n",
      "Media                         661\n",
      "Social Issues                 627\n",
      "Immigration                   626\n",
      "Technology                    512\n",
      "no_topic                      460\n",
      "Lifestyle                     420\n",
      "Economy                       381\n",
      "Accident                      344\n",
      "Science                       263\n",
      "Safety                        203\n",
      "Disaster                      190\n",
      "Transportation                183\n",
      "Community                     178\n",
      "Labor                         174\n",
      "Travel                        157\n",
      "Finance                       130\n",
      "Infrastructure                124\n",
      "Obituary                      117\n",
      "Society                       116\n",
      "Food                           98\n",
      "Arts                           90\n",
      "Public Safety                  76\n",
      "History                        75\n",
      "Housing                        53\n",
      "Charity                        52\n",
      "Natural Disasters              51\n",
      "International Relations        49\n",
      "Social                         47\n",
      "Economics                      46\n",
      "Animal Rights                  45\n",
      "Natural Disaster               45\n",
      "No_topic                       40\n",
      "Disasters and Emergencies      35\n",
      "Military                       33\n",
      "Human Rights                   24\n",
      "Consumer                       22\n",
      "International                  22\n",
      "Wildlife                       22\n",
      "Family                         21\n",
      "Human Interest                 20\n",
      "Religion                       19\n",
      "Real Estate                    15\n",
      "Food & Dining                  15\n",
      "Animal                         14\n",
      "Cybersecurity                  14\n",
      "Accidents                      14\n",
      "Fashion                        14\n",
      "Agriculture                    13\n",
      "Animal Welfare                 12\n",
      "Healthcare                     12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set the max rows to 100 (or any number higher than 62)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Now run your command\n",
    "print(df['topic_cat'].value_counts()[:62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b822fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    # 1. Politics & Global Affairs (Added 'Government')\n",
    "    'Politics': 'Politics',\n",
    "    'International Relations': 'Politics',\n",
    "    'International': 'Politics',\n",
    "    'Government': 'Politics',\n",
    "\n",
    "    # 2. Crime & Safety\n",
    "    'Crime': 'Crime & Safety',\n",
    "    'Safety': 'Crime & Safety',\n",
    "    'Public Safety': 'Crime & Safety',\n",
    "    'Security': 'Crime & Safety',\n",
    "    'Cybersecurity': 'Crime & Safety',\n",
    "\n",
    "    # 3. Legal\n",
    "    'Legal': 'Legal',\n",
    "\n",
    "    # 4. Business & Economy (Added 'Consumer')\n",
    "    'Business': 'Business & Economy',\n",
    "    'Economy': 'Business & Economy',\n",
    "    'Economics': 'Business & Economy',\n",
    "    'Finance': 'Business & Economy',\n",
    "    'Labor': 'Business & Economy',\n",
    "    'Consumer': 'Business & Economy',\n",
    "\n",
    "    # 5. Sports\n",
    "    'Sports': 'Sports',\n",
    "\n",
    "    # 6. Health\n",
    "    'Health': 'Health',\n",
    "    'Healthcare': 'Health',\n",
    "\n",
    "    # 7. Entertainment (Added 'Celebrity')\n",
    "    'Entertainment': 'Entertainment',\n",
    "    'Celebrity': 'Entertainment',\n",
    "\n",
    "    # 8. Lifestyle & Culture\n",
    "    'Culture': 'Lifestyle & Culture',\n",
    "    'Lifestyle': 'Lifestyle & Culture',\n",
    "    'Travel': 'Lifestyle & Culture',\n",
    "    'Food': 'Lifestyle & Culture',\n",
    "    'Arts': 'Lifestyle & Culture',\n",
    "    'Fashion': 'Lifestyle & Culture',\n",
    "    'History': 'Lifestyle & Culture',\n",
    "    'Religion': 'Lifestyle & Culture',\n",
    "    'Family': 'Lifestyle & Culture',\n",
    "    'Human Interest': 'Lifestyle & Culture',\n",
    "    'Obituary': 'Lifestyle & Culture',\n",
    "\n",
    "    # 9. Environment & Nature (Added 'Animals')\n",
    "    'Environment': 'Environment & Nature',\n",
    "    'Wildlife': 'Environment & Nature',\n",
    "    'Animal Rights': 'Environment & Nature',\n",
    "    'Animal': 'Environment & Nature',\n",
    "    'Animals': 'Environment & Nature',\n",
    "    'Animal Welfare': 'Environment & Nature',\n",
    "    'Agriculture': 'Environment & Nature',\n",
    "\n",
    "    # 10. War & Conflict\n",
    "    'War': 'War & Conflict',\n",
    "    'Military': 'War & Conflict',\n",
    "\n",
    "    # 11. Science & Technology\n",
    "    'Technology': 'Science & Technology',\n",
    "    'Science': 'Science & Technology',\n",
    "\n",
    "    # 12. Disaster & Accidents\n",
    "    'Accident': 'Disaster & Accidents',\n",
    "    'Accidents': 'Disaster & Accidents',\n",
    "    'Disaster': 'Disaster & Accidents',\n",
    "    'Disasters and Emergencies': 'Disaster & Accidents',\n",
    "    'Natural Disasters': 'Disaster & Accidents',\n",
    "    'Natural Disaster': 'Disaster & Accidents',\n",
    "    'Emergency': 'Disaster & Accidents',\n",
    "\n",
    "    # 13. Social Issues (Added 'Humanitarian')\n",
    "    'Social Issues': 'Social Issues',\n",
    "    'Social': 'Social Issues',\n",
    "    'Society': 'Social Issues',\n",
    "    'Community': 'Social Issues',\n",
    "    'Charity': 'Social Issues',\n",
    "    'Human Rights': 'Social Issues',\n",
    "    'Humanitarian': 'Social Issues',\n",
    "\n",
    "    # 14. Infrastructure & Transport\n",
    "    'Transportation': 'Infrastructure & Transport',\n",
    "    'Infrastructure': 'Infrastructure & Transport',\n",
    "    'Housing': 'Infrastructure & Transport',\n",
    "    'Urban Development': 'Infrastructure & Transport',\n",
    "\n",
    "    # 15. Independent Mid-Sized Categories\n",
    "    'Weather': 'Weather',\n",
    "    'Education': 'Education',\n",
    "    'Media': 'Media',\n",
    "    'Immigration': 'Immigration',\n",
    "\n",
    "    # 16. Handling Nulls/Other\n",
    "    'no_topic': 'Other/Unknown',\n",
    "    'No_topic': 'Other/Unknown'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "579c55b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_topic\n",
      "Politics                      4561\n",
      "Crime & Safety                4110\n",
      "Sports                        3762\n",
      "Business & Economy            2406\n",
      "Lifestyle & Culture           1897\n",
      "Legal                         1816\n",
      "Health                        1615\n",
      "Entertainment                 1342\n",
      "Environment & Nature          1315\n",
      "Social Issues                  963\n",
      "War & Conflict                 885\n",
      "Science & Technology           690\n",
      "Disaster & Accidents           681\n",
      "Weather                        671\n",
      "Education                      653\n",
      "Media                          641\n",
      "Immigration                    636\n",
      "Other/Unknown                  467\n",
      "Infrastructure & Transport     379\n",
      "Food & Dining                   14\n",
      "Local News                      12\n",
      "Events                          12\n",
      "Energy                          10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count        29538\n",
       "unique          23\n",
       "top       Politics\n",
       "freq          4561\n",
       "Name: cleaned_topic, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the new column\n",
    "df['cleaned_topic'] = df['topic_cat'].map(category_mapping)\n",
    "\n",
    "# IMPORTANT: .map() converts anything NOT in the dictionary to NaN (missing).\n",
    "# If you have topics in your data that are NOT in the list above, fill them with the original value:\n",
    "df['cleaned_topic'] = df['cleaned_topic'].fillna(df['topic_cat'])\n",
    "\n",
    "# set dtype\n",
    "df['cleaned_topic'] = df['cleaned_topic'].astype('category')\n",
    "\n",
    "# Check your new reduced value counts\n",
    "print(df['cleaned_topic'].value_counts())\n",
    "\n",
    "df['cleaned_topic'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de21ee",
   "metadata": {},
   "source": [
    "Now let's reload the dataloaders with this new set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "511f1493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business & Economy': 0,\n",
       " 'Crime & Safety': 1,\n",
       " 'Disaster & Accidents': 2,\n",
       " 'Education': 3,\n",
       " 'Entertainment': 4,\n",
       " 'Environment & Nature': 5,\n",
       " 'Food & Dining': 6,\n",
       " 'Health': 7,\n",
       " 'Immigration': 8,\n",
       " 'Infrastructure & Transport': 9,\n",
       " 'Legal': 10,\n",
       " 'Lifestyle & Culture': 11,\n",
       " 'Media': 12,\n",
       " 'Other/Unknown': 13,\n",
       " 'Politics': 14,\n",
       " 'Real Estate': 15,\n",
       " 'Science & Technology': 16,\n",
       " 'Social Issues': 17,\n",
       " 'Sports': 18,\n",
       " 'War & Conflict': 19,\n",
       " 'Weather': 20}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rereate label_ids mapping (string --> int)\n",
    "label_ids = df['cleaned_topic'].cat.codes\n",
    "id_to_label = list(df['cleaned_topic'].cat.categories)\n",
    "label_to_id = {label: i for i, label in enumerate(id_to_label)}\n",
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79c741ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23626 2953 2954\n"
     ]
    }
   ],
   "source": [
    "# recreate the dataset\n",
    "\n",
    "# Redo the test_train split since indices have to be stratified\n",
    "# integer-coded labels aligned with encodings order\n",
    "labels = np.array(label_ids, dtype=np.int64) # numpy array\n",
    "\n",
    "N = len(labels)\n",
    "idx = np.arange(N)\n",
    "\n",
    "# 80/10/10 split (train/val/test), stratified\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    idx,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=labels # as array\n",
    ")\n",
    "\n",
    "# Run it again on the temp test set to get the val set\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx,\n",
    "    test_size=0.50,                    # half of 20% -> 10% val, 10% test\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=labels[temp_idx]\n",
    ")\n",
    "\n",
    "# Build ONE dataset, then slice with Subset\n",
    "full_df = NewsArticleDataset(encodings, label_ids)  # or NewsArticleDataset(encodings, labels)\n",
    "train = Subset(full_df, train_idx) # basically does what it says on the tin\n",
    "val   = Subset(full_df, val_idx)\n",
    "test  = Subset(full_df, test_idx)\n",
    "print(len(train), len(val), len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9be8728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate the data loader, they rely on dataset + indices\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train, \n",
    "                          batch_size = batch_size, # number of articles to be fed into the model at once\n",
    "                          num_workers=0, # increase this later on\n",
    "                          shuffle = True, \n",
    "                          pin_memory= True)\n",
    "val_loader = DataLoader(val, \n",
    "                          batch_size = batch_size, # number of articles to be fed into the model at once\n",
    "                          shuffle = False, # false so eval is deterministic and reproducible\n",
    "                          pin_memory= True)\n",
    "test_loader = DataLoader(test, \n",
    "                          batch_size = batch_size, # number of articles to be fed into the model at once\n",
    "                          shuffle = False,  # false, as above\n",
    "                          pin_memory= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb23d1",
   "metadata": {},
   "source": [
    "### New training loop after debugs/changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f11504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# reset model \n",
    "# recreate the model head \n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=19)\n",
    "model.to('cuda')\n",
    "\n",
    "# set optimizer  and LR\n",
    "optimizer = torch.optim.AdamW(lr=2e-5, # for transformers, we want a low learning rate, even lower than 0.001\n",
    "                              weight_decay= 0.01, # this basically is L2 regularization applied through, penalizeing large weight, encouragin params to stay smaller, can help reduce overfitting and improve generalization\n",
    "                             params=model.parameters()) # tell the optimizer what parameters to optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5750eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "\n",
    "#     running_loss = 0.0\n",
    "\n",
    "#     for batch in train_loader:\n",
    "#         # 1) move batch to GPU\n",
    "#         batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "\n",
    "#         # 2) forward pass \n",
    "#         outputs = model(\n",
    "#             input_ids=batch[\"input_ids\"],\n",
    "#             attention_mask=batch[\"attention_mask\"],\n",
    "#             labels=batch[\"labels\"] # had a rough comma here b4\n",
    "#         )\n",
    "\n",
    "#         loss = outputs.loss # default loss from the HF auto model, likely cross entropy\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#         # 3) zero grad\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # 4) backward\n",
    "#         loss.backward()\n",
    "\n",
    "#         # 5) step\n",
    "#         optimizer.step()\n",
    "\n",
    "#     # ---- validation ----\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in val_loader:\n",
    "#             batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "#             outputs = model(\n",
    "#                 input_ids=batch[\"input_ids\"],\n",
    "#                 attention_mask=batch[\"attention_mask\"],\n",
    "#                 labels=batch[\"labels\"],\n",
    "#             )\n",
    "#             val_loss += outputs.loss.item()\n",
    "\n",
    "#             logits = outputs.logits\n",
    "#             preds = logits.argmax(dim=-1)\n",
    "#             correct += (preds == batch[\"labels\"]).sum().item()\n",
    "#             total += batch[\"labels\"].size(0)\n",
    "\n",
    "#     print(\n",
    "#         f\"Epoch {epoch} | train_loss={running_loss/len(train_loader):.4f} \"\n",
    "#         f\"| val_loss={val_loss/len(val_loader):.4f} | val_acc={correct/total:.4f}\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cafc39",
   "metadata": {},
   "source": [
    "Notes on this training run:\n",
    "* seems we can work with batch size of 32 reasonably well, dedicated GPU memory around 65%\n",
    "* we could probably push the epochs further with the above set-up, but now that this is working, it's better to implement some more intelligent improvements\n",
    "\n",
    "Specifically:\n",
    "* Early-stopping + best checkpoint (by val_loss)\n",
    "* Macro-F1 (and accuracy) on validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76ab63",
   "metadata": {},
   "source": [
    "### Refined training run #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8ae0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding in early stopping and model checkpoint (minimizing val_loss)\n",
    "\n",
    "import copy\n",
    "import math\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, min_delta=0.0):\n",
    "        self.patience = patience # how long we wait to see if val improves\n",
    "        self.min_delta = min_delta\n",
    "        self.best = math.inf # track best loss, inf on init\n",
    "        self.bed_epochs = 0\n",
    "        self.best_state = None\n",
    "    def step(self, val_loss, model):\n",
    "        improved = val_loss < (self.best - self.min_delta)\n",
    "        if improved:\n",
    "            self.best = val_loss\n",
    "            self.bad_epochs = 0\n",
    "            # keep weights in memory for recent best model\n",
    "            self.best_state = copy.deepcopy(model.state_dict()) # state dict is our parameters\n",
    "        else:\n",
    "            self.bed_epochs += 1\n",
    "        return self.bed_epochs >= self.patience # returns boolean on whether to continue or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea2da15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dedicate GPU memory is growing so lets reset it \n",
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4dcc087e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSequenceClassification\n\u001b[32m      5\u001b[39m model = AutoModelForSequenceClassification.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mdistilbert-base-uncased\u001b[39m\u001b[33m\"\u001b[39m, num_labels=\u001b[32m19\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# set optimizer  and LR\u001b[39;00m\n\u001b[32m      9\u001b[39m optimizer = torch.optim.AdamW(lr=\u001b[32m2e-5\u001b[39m, \u001b[38;5;66;03m# for transformers, we want a low learning rate, even lower than 0.001\u001b[39;00m\n\u001b[32m     10\u001b[39m                               weight_decay= \u001b[32m0.01\u001b[39m, \u001b[38;5;66;03m# this basically is L2 regularization applied through, penalizeing large weight, encouragin params to stay smaller, can help reduce overfitting and improve generalization\u001b[39;00m\n\u001b[32m     11\u001b[39m                              params=model.parameters()) \u001b[38;5;66;03m# tell the optimizer what parameters to optimize\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\transformers\\modeling_utils.py:4343\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   4338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   4339\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4340\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4341\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4342\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m4343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1337\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1338\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1340\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    899\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    904\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    911\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    899\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    904\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    911\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    899\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    904\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    911\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    924\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    925\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    930\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1320\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1321\u001b[39m             device,\n\u001b[32m   1322\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m             non_blocking,\n\u001b[32m   1324\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1325\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# reset model \n",
    "# recreate the model head \n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=19)\n",
    "model.to('cuda')\n",
    "\n",
    "# set optimizer  and LR\n",
    "optimizer = torch.optim.AdamW(lr=2e-5, # for transformers, we want a low learning rate, even lower than 0.001\n",
    "                              weight_decay= 0.01, # this basically is L2 regularization applied through, penalizeing large weight, encouragin params to stay smaller, can help reduce overfitting and improve generalization\n",
    "                             params=model.parameters()) # tell the optimizer what parameters to optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bc84d8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# 1) move batch to GPU\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     batch = \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# 2) forward pass \u001b[39;00m\n\u001b[32m     18\u001b[39m     outputs = model(\n\u001b[32m     19\u001b[39m         input_ids=batch[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     20\u001b[39m         attention_mask=batch[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     21\u001b[39m         labels=batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;66;03m# had a rough comma here b4\u001b[39;00m\n\u001b[32m     22\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     11\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# 1) move batch to GPU\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     batch = {k: \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch.items()}\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# 2) forward pass \u001b[39;00m\n\u001b[32m     18\u001b[39m     outputs = model(\n\u001b[32m     19\u001b[39m         input_ids=batch[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     20\u001b[39m         attention_mask=batch[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     21\u001b[39m         labels=batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;66;03m# had a rough comma here b4\u001b[39;00m\n\u001b[32m     22\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "## FULL TRAINING LOOP WITH MACRO F1 (and accuracy) ON VALIDATION\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "early = EarlyStopper(patience=8, min_delta=0.0)\n",
    "max_epochs = 15\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # 1) move batch to GPU\n",
    "        batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "\n",
    "        # 2) forward pass \n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"] # had a rough comma here b4\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss # default loss from the HF auto model, likely cross entropy\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 3) zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4) backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5) step\n",
    "        optimizer.step()\n",
    "\n",
    "    # ---- new validation process ----\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                labels=batch[\"labels\"]\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            all_preds.append(preds.detach().cpu().numpy())\n",
    "            all_labels.append(batch['labels'].detach().cpu().numpy())\n",
    "            val_loss += outputs.loss.item() \n",
    "    val_loss_mean = val_loss / len(val_loader)\n",
    "\n",
    "            \n",
    "            \n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    val_acc = accuracy_score(all_labels, all_preds)\n",
    "    val_f1_macro = f1_score(all_labels, all_preds, average = \"macro\")\n",
    "    val_f1_weighted = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "        \n",
    "    print(\n",
    "        f\"Epoch {epoch} | train_loss_mean ={running_loss/len(train_loader):.3f} \"\n",
    "        f\"| val_acc={val_acc:.3f} | val_f1_macro={val_f1_macro:.3f} | val_f1_weighted = {val_f1_weighted:.3f} |\"\n",
    "        f\"val_loss = {val_loss_mean:.3f}\")\n",
    "    \n",
    "    should_stop = early.step(val_loss_mean, model) # should be mean here?\n",
    "    \n",
    "    if should_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaace376",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Getting best model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m(early.best_state)\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "## Getting best model\n",
    "model.load_state_dict(early.best_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618c1b4",
   "metadata": {},
   "source": [
    "Notes on this training run:\n",
    "\n",
    "* Hitting an overfitting wall, which measn we probably do need some regularization\n",
    "* DistillBERT, being a smaller size than bert base, might lack the size to capture the subtle boundaries between categories\n",
    "\n",
    "\n",
    "\n",
    "Next steps:\n",
    "\n",
    "* Explore newer BERT classification models (like zero-shot models that don't need to be pre-trained! investigating `\"MoritzLaurer/deberta-v3-base-zeroshot-v2.0\"`)\n",
    "\n",
    "* We could move to a much larger model like bigbird or longformer, but at this point, I'm not convinced that it's actually the truncation that is causing this problem, as topic modelling should be fairly simple\n",
    "\n",
    "* Implement regularization via dropout probabilities in the config\n",
    "\n",
    "* Also thinking that we could just inspect the data, is it struggling with very short texts, for instance? are labels correct and can we process them?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb235f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try it on the test set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3bc94",
   "metadata": {},
   "source": [
    "### Training Run #3 - testing one-shot classifier model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
