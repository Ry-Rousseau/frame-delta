{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa3386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: news-please in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (1.6.16)\n",
      "Requirement already satisfied: numpy in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: Scrapy>=1.1.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (2.13.4)\n",
      "Requirement already satisfied: PyMySQL>=0.7.9 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (1.1.2)\n",
      "Requirement already satisfied: psycopg2-binary>=2.8.4 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (2.9.11)\n",
      "Requirement already satisfied: hjson>=1.5.8 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (3.1.0)\n",
      "Requirement already satisfied: elasticsearch>=2.4 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (9.2.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.3.2 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (4.13.5)\n",
      "Requirement already satisfied: readability-lxml>=0.6.2 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (0.8.4.1)\n",
      "Requirement already satisfied: langdetect>=1.0.7 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (1.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.4.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (2.9.0.post0)\n",
      "Requirement already satisfied: plac>=0.9.6 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (1.4.5)\n",
      "Requirement already satisfied: dotmap>=1.2.17 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (1.3.30)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (2.0.7)\n",
      "Requirement already satisfied: warcio>=1.3.3 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (1.7.5)\n",
      "Requirement already satisfied: ago>=0.0.9 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (0.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (1.17.0)\n",
      "Requirement already satisfied: lxml>=3.3.5 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (6.0.2)\n",
      "Requirement already satisfied: hurry.filesize>=0.9 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (0.9)\n",
      "Requirement already satisfied: bs4 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (0.0.2)\n",
      "Requirement already satisfied: faust-cchardet>=2.1.18 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (2.1.19)\n",
      "Requirement already satisfied: boto3 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (1.42.21)\n",
      "Requirement already satisfied: redis in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (7.1.0)\n",
      "Requirement already satisfied: newspaper4k>=0.9.3.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (0.9.4.1)\n",
      "Requirement already satisfied: lxml-html-clean>=0.1.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (0.4.3)\n",
      "Requirement already satisfied: pywin32>=220 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from news-please) (311)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from beautifulsoup4>=4.3.2->news-please) (2.5)\n",
      "Requirement already satisfied: elastic-transport<10,>=9.2.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from elasticsearch>=2.4->news-please) (9.2.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from elasticsearch>=2.4->news-please) (1.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from elastic-transport<10,>=9.2.0->elasticsearch>=2.4->news-please) (2.5.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from hurry.filesize>=0.9->news-please) (80.9.0)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from newspaper4k>=0.9.3.1->news-please) (1.2.0)\n",
      "Requirement already satisfied: feedparser>=6.0.2 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from newspaper4k>=0.9.3.1->news-please) (6.0.12)\n",
      "Requirement already satisfied: nltk>=3.6.6 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from newspaper4k>=0.9.3.1->news-please) (3.9.2)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from newspaper4k>=0.9.3.1->news-please) (5.3.1)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from feedparser>=6.0.2->newspaper4k>=0.9.3.1->news-please) (1.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (2025.10.23)\n",
      "Requirement already satisfied: chardet in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from readability-lxml>=0.6.2->news-please) (5.2.0)\n",
      "Requirement already satisfied: cssselect in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from readability-lxml>=0.6.2->news-please) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=37.0.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (46.0.3)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (0.7.1)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (0.13.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (1.3.2)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (1.10.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (0.5.0)\n",
      "Requirement already satisfied: pyopenssl>=22.0.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (25.3.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (1.8.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (24.2.0)\n",
      "Requirement already satisfied: twisted<=25.5.0,>=21.7.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (25.5.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (2.3.1)\n",
      "Requirement already satisfied: zope-interface>=5.1.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from Scrapy>=1.1.0->news-please) (8.1.1)\n",
      "Requirement already satisfied: automat>=24.8.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from twisted<=25.5.0,>=21.7.0->Scrapy>=1.1.0->news-please) (25.4.16)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from twisted<=25.5.0,>=21.7.0->Scrapy>=1.1.0->news-please) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from twisted<=25.5.0,>=21.7.0->Scrapy>=1.1.0->news-please) (21.0.0)\n",
      "Requirement already satisfied: incremental>=24.7.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from twisted<=25.5.0,>=21.7.0->Scrapy>=1.1.0->news-please) (24.11.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from cryptography>=37.0.0->Scrapy>=1.1.0->news-please) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from cffi>=2.0.0->cryptography>=37.0.0->Scrapy>=1.1.0->news-please) (2.23)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from itemloaders>=1.0.1->Scrapy>=1.1.0->news-please) (1.0.1)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please) (0.4.2)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from tldextract>=2.0.1->newspaper4k>=0.9.3.1->news-please) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.21 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from boto3->news-please) (1.42.21)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from boto3->news-please) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rhrou\\miniconda3\\envs\\torch-gpu\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch news-please numpy pandas datasets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8a5cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rhrou\\miniconda3\\envs\\torch-gpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "tensor([[-0.8820, -0.8982,  0.5360],\n",
      "        [-0.5079, -0.3259, -1.3447],\n",
      "        [-0.0790,  0.3232,  0.3885]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # looks for .env in current directory or parents\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "print(torch.randn(3,3))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35da3d",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Dataset source: [Data](https://huggingface.co/datasets/copenlu/mm-framing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c914a305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'uuid': '0000442d-4ce2-4d1c-b654-5561c3cab3b7',\n",
       "  'title': 'NJ community teams up to help repair historic cemetery damaged by August storms',\n",
       "  'date_publish': '2023-08-23 22:25:00',\n",
       "  'source_domain': 'www.cbsnews.com',\n",
       "  'url': 'https://www.cbsnews.com/philadelphia/video/nj-community-teams-up-to-help-repair-historic-cemetery-damaged-by-august-storms/',\n",
       "  'political_leaning': 'left_lean',\n",
       "  'text-topic': 'Historic Cemetery Damage and Restoration',\n",
       "  'text-topic-exp': \"The article discusses the damage caused to a historic cemetery by storms and the community's efforts to repair it. The cemetery is significant as it is the final resting place of several black Civil War veterans.\",\n",
       "  'text-entity-name': \"Woodstown church's historic cemetery\",\n",
       "  'text-entity-sentiment': 'Positive',\n",
       "  'text-entity-sentiment-exp': 'The article describes efforts to repair and clean up the cemetery, indicating a positive sentiment towards the entity.',\n",
       "  'text-generic-frame': \"['Economic', 'Health and safety', 'Cultural identity', 'Public Opinion']\",\n",
       "  'text-generic-frame-exp': \"The article discusses the financial implications of repairing the cemetery ('Economic'), the health and safety concerns related to the damaged cemetery ('Health and safety'), the cultural significance of the cemetery as the final resting place of black Civil War veterans ('Cultural identity'), and the involvement of CBS News Philadelphia, which may reflect public opinion ('Public Opinion').\",\n",
       "  'text-issue-frame': 'Historic Preservation',\n",
       "  'text-issue-frame-exp': \"The article focuses on the repair of a historic cemetery, specifically mentioning it as the final resting place of several black Civil War veterans. This framing emphasizes the importance of preserving historical sites and honoring the legacy of those who have contributed to history, in this case, black Civil War veterans. The use of the term 'historic' in the title also supports this framing.\",\n",
       "  'img-generic-frame': \"['None', 'Capacity and resources', 'Morality']\",\n",
       "  'img-frame-exp': 'The image shows a cemetery with fallen trees and gravestones, indicating damage and disruption to a place of burial. This suggests issues related to the availability of resources (trees, maintenance) and the moral or ethical implications of such disruptions in a place of rest.',\n",
       "  'img-entity-name': None,\n",
       "  'img-entity-sentiment': 'negative',\n",
       "  'img-entity-sentiment-exp': 'The fallen tree and the damage to the gravestones suggest a destructive event, which typically conveys a negative sentiment.',\n",
       "  'gpt-topic': 'Culture'},\n",
       " datasets.arrow_dataset.Dataset)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this loads data as an apache arrow format, mapping to disk\n",
    "data = load_dataset(\"copenlu/mm-framing\")\n",
    "data_raw = data\n",
    "data = data['full']\n",
    "data[1], type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7e8505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478856"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9678f",
   "metadata": {},
   "source": [
    "### Hydrating the urls test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c4dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For someone whose affably rumpled appearance suggests Matt Damon waking up from a nap, the comedian Mike Birbiglia is remarkably industrious. He is a film-maker (movies include Don’t Think Twice, a comedy about an improv group starring Keegan-Michael Key) and an actor (The Fault in Our Stars, Orange Is the New Black), and he recently played Taylor Swift’s avaricious son, who discovers at her funeral that he has been left out of her will, in the video for Anti-Hero. He also has a podcast, The Old Ones, in which celebrity guests pick apart his earlier standup routines, and another, Working It Out, in which they help him develop new material. “Like Tom Sawyer getting his friends to paint the fence,” as one guest, Nathan Lane, memorably put it.\n",
      "Now the 45-year-old is bringing his latest show, The Old Man and the Pool, to the UK after a sell-out Broadway run. If he had his way, he wouldn’t reveal anything about it in advance. “I’d just say, ‘I wrote a show about mortality and I guarantee you’ll laugh for 80 minutes straight and sometimes people also feel emotions from it and – trust me – I think you’ll love it.’” He is speaking to me from his Brooklyn apartment, a large ceiling fan whirring sleepily above him so that it looks like his head has propellers.\n",
      "Millions trust Birbiglia already. This is his fifth show, with three of the others – My Girlfriend’s Boyfriend, Thank God for Jokes and The New One – available as Netflix specials. His routines are intimate and convivial, peppered with delicious phrasing and zinging observations. He talks on stage about his wife, the poet J Hope Stein, whose soothing voice has “a thread-count of 600”; he bemoans the arrogance of the bed, the only item of furniture to have an entire room named after it; and he makes good-egg, commonsense arguments, such as his plea against tardiness: “It’s so easy to be on time because all you have to do is be early – and ‘early’ lasts for hours.”\n",
      "The Old Man and the Pool begins with a catastrophic midlife MOT. Healthcare appointments usually spell trouble for Birbiglia, who had bladder cancer at the age of 20 and still suffers from a severe sleep-walking disorder that requires him to go to bed each night in a sleeping bag while wearing mittens to prevent him from unzipping himself. Prior to his diagnosis, he once jumped through a closed second-storey window of his hotel room while asleep.\n",
      "This time around, he has pulmonary issues. “The doctor asked me to blow into a tube,” he recalls. “Then he said, ‘If I was going just by this, I’d say you’re having a heart attack right now.’ I did it a second time and he said, ‘I don’t know what to tell you…’” There was reason to worry: his father had his first heart attack in his 50s, while his grandfather suffered a fatal one around the same age. “He worked in a bodega in Brooklyn. One day a regular came in and said, ‘How’s it going, Joe?’ And he keeled over the counter and died. Which is sad but, in a way, also the funniest response you could possibly have. I think of him as the original comedian of the family. That is an extraordinary level of commitment.”\n",
      "To add to his problems, Birbiglia was also diagnosed with type 2 diabetes. Cue a tale of fear, panic and grudging exercise at his local YMCA, which gives the show its Hemingway-riffing title and makes possible the eye-catching set: a tiled tidal wave looming over Birbiglia. (Think of it as the pool of Damocles.) The heavy stuff is leavened by his springy delivery and niceness, though he bristles slightly when I use that word: “I don’t know if the audience needs me to be ‘nice’ so much as ‘human’.”\n",
      "There are also odes to blissful domesticity: he and Stein have an eight-year-old daughter, Oona, whose birth was the subject of The New One, and whose chit-chat features in the latest show without tipping too far into kids-say-the-funniest-things terrain. Today, he is wearing a bracelet she made for him, its beads spelling out the word “silly”– a daily reminder to salt his talk of death with daftness, and one he has no trouble heeding.\n",
      "Indeed, audiences will rarely have laughed so much while being invited to contemplate their own extinction. “All my shows,” he says, “are about the value of fearlessness when it comes to being truthful with the people you love, and how that can make us closer to each other. But this show is like the icebreaker of all icebreakers. If you don’t have a deep conversation afterwards with the person you came in with, then you probably never will.”\n",
      "https://www.theguardian.com/stage/2023/aug/22/standup-mike-birbiglia-sleep-jumped-broadway-smash-doc-heart-attack\n"
     ]
    }
   ],
   "source": [
    "from newsplease import NewsPlease\n",
    "test_index = 2\n",
    "\n",
    "url = data[test_index][\"url\"]\n",
    "\n",
    "article = NewsPlease.from_url(url)\n",
    "\n",
    "print(article.maintext)\n",
    "print(url)\n",
    "data[test_index]\n",
    "\n",
    "def get_article_text(url):\n",
    "    text = NewsPlease.from_url(url)\n",
    "    return(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b82790",
   "metadata": {},
   "source": [
    "After checking several examples of the text, it seems that a large portion of the news are non-political, include videos, or aren't very long. Seems to be a flaw with the original paper. \n",
    "\n",
    "TO DO: Filter the dataset to get just the truly 'political' news stories\n",
    "\n",
    "TO DO: Check out the other dataset, the 'validation' set to see if it different in terms of its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb0aa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uuid': '019a66c8-1d6f-42f7-ae2c-ade5b91d6b45',\n",
       " 'title': 'Florida neighborhood terrorized after crocodile eats small dog',\n",
       " 'date_publish': '2023-08-02 16:09:12',\n",
       " 'source_domain': 'www.foxnews.com',\n",
       " 'url': 'https://www.foxnews.com/us/florida-neighborhood-terrorized-crocodile-eats-small-dog',\n",
       " 'political_leaning': 'right',\n",
       " 'text-topic': 'Crocodile Attack',\n",
       " 'text-topic-exp': \"The article discusses an incident where a crocodile ate a small dog in a Florida canal, and it includes quotes from witnesses and the Florida Fish and Wildlife Conservation Commission's response to the incident.\",\n",
       " 'text-entity-name': 'Crocodile',\n",
       " 'text-entity-sentiment': 'negative',\n",
       " 'text-entity-sentiment-exp': 'The crocodile is portrayed as a dangerous and harmful entity that caused the death of a pet dog and caused concern among the residents of Satellite Beach, Florida.',\n",
       " 'text-generic-frame': \"['crime', 'security', 'public_op']\",\n",
       " 'text-generic-frame-exp': \"The article discusses an incident of a crocodile eating a small dog, which is a crime and punishment issue as it involves the violation of property rights (pet ownership). The community's concern and fear towards the crocodile's presence also indicates a security and defense issue. The public's reactions and opinions are also presented throughout the article, making it a Public Opinion frame.\",\n",
       " 'text-issue-frame': 'Dangerous Wildlife',\n",
       " 'text-issue-frame-exp': \"The article focuses on a crocodile that has attacked a pet dog in a residential area, causing concern among the community. The repeated use of words like 'danger', 'terrifying', and the investigation by the Florida Fish and Wildlife Conservation Commission all contribute to framing the issue as a threat to public safety, which aligns with the 'Dangerous Wildlife' frame.\",\n",
       " 'img-generic-frame': \"['quality_life']\",\n",
       " 'img-frame-exp': 'The image depicts a serene residential area with a house and a dock by the water, suggesting a high quality of life. There are no specific indicators of other frames such as health and safety, policy prescription, or political activities.',\n",
       " 'img-entity-name': None,\n",
       " 'img-entity-sentiment': 'neutral',\n",
       " 'img-entity-sentiment-exp': 'The image depicts a serene residential area with houses and a lake, without any specific focus on a particular individual or organization. The overall atmosphere appears calm and neutral.',\n",
       " 'gpt-topic': 'Crime'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw['valid_framing_subset'][150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903bd05",
   "metadata": {},
   "source": [
    "So it seems that the validation set is similar in having non-political articles\n",
    "\n",
    "\n",
    "For now, run with just a subset of the data. Ignore this issue. Parse later before full training runs.\n",
    "\n",
    "In order to create a hydrated version of the data, bu keep the arrow datasets (which are immutable), then we use a .map() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ca7260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to hydrate URLs...\n",
      "Hydration complete!\n"
     ]
    }
   ],
   "source": [
    "# Create a minimal dataset to process in this notebook with hydrated article text\n",
    "import time\n",
    "from newsplease import NewsPlease\n",
    "\n",
    "def scrape_and_add(example):\n",
    "    \"\"\"Scrape article text from URL with error handling\"\"\"\n",
    "    url = example['url']\n",
    "\n",
    "    try:\n",
    "        # Add a small delay to avoid rate limiting\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Try to fetch the article\n",
    "        article = NewsPlease.from_url(url)\n",
    "\n",
    "        # Return the maintext if available, otherwise empty string\n",
    "        if article and article.maintext:\n",
    "            return {\"article_text\": article.maintext}\n",
    "        else:\n",
    "            print(f\"No text found for: {url}\")\n",
    "            return {\"article_text\": \"\"}\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle 403s and other errors gracefully\n",
    "        print(f\"Error fetching {url}: {type(e).__name__} - {str(e)}\")\n",
    "        return {\"article_text\": \"\"}\n",
    "\n",
    "# Create a small dataset for testing\n",
    "df = data.shuffle(seed=42).select(range(25))\n",
    "\n",
    "# Apply the scraping function to each row (batched=False means one at a time)\n",
    "print(\"Starting to hydrate URLs...\")\n",
    "df = df.map(scrape_and_add, batched=False)\n",
    "print(\"Hydration complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a49a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uuid': '71f2fc7a-72e4-4001-9a1a-ab2c962c81de',\n",
       " 'title': '\"People\" magazine editor-in-chief shares exclusive excerpts from Britney Spears\\' new memoir',\n",
       " 'date_publish': '2023-10-17 12:30:00',\n",
       " 'source_domain': 'www.cbsnews.com',\n",
       " 'url': 'https://www.cbsnews.com/video/people-magazine-editor-in-chief-shares-exclusive-excerpts-from-britney-spears-new-memoir/',\n",
       " 'political_leaning': 'left_lean',\n",
       " 'text-topic': 'Britney Spears',\n",
       " 'text-topic-exp': \"The article is about an exclusive excerpt from Britney Spears' new memoir and a recent interview and cover shoot with her, as shared by the editor-in-chief of 'People' magazine.\",\n",
       " 'text-entity-name': 'Britney Spears',\n",
       " 'text-entity-sentiment': None,\n",
       " 'text-entity-sentiment-exp': 'The article does not provide enough context to determine the sentiment towards Britney Spears.',\n",
       " 'text-generic-frame': \"['Cultural identity', 'Public Opinion']\",\n",
       " 'text-generic-frame-exp': \"The article discusses Britney Spears, a cultural icon, and her memoir, which reveals personal insights about her life. This falls under the 'Cultural identity' frame. Additionally, the article mentions an interview and cover shoot with Spears, indicating a focus on public opinion and the general public's interest in her, which falls under the 'Public Opinion' frame.\",\n",
       " 'text-issue-frame': 'Personal Triumph',\n",
       " 'text-issue-frame-exp': \"The article focuses on Britney Spears' new memoir, which is a personal account of her life experiences. The use of the word 'explosive' suggests a revealing and potentially empowering narrative. The sharing of 'exclusive excerpts' and a 'recent interview and cover shoot' further emphasizes the personal nature of the story, making 'Personal Triumph' an appropriate issue-specific frame.\",\n",
       " 'img-generic-frame': \"['None']\",\n",
       " 'img-frame-exp': 'The image shows a person in a professional setting, but there are no specific indicators related to any of the listed frames such as financial institutions, policy discussions, or other identifiable elements.',\n",
       " 'img-entity-name': 'Female Interviewer',\n",
       " 'img-entity-sentiment': 'positive',\n",
       " 'img-entity-sentiment-exp': 'The subject is smiling, which indicates a positive sentiment.',\n",
       " 'gpt-topic': 'Entertainment',\n",
       " 'article_text': '\"People\" magazine\\'s editor-in-chief Wendy Naugle joins \"CBS Mornings\" to share exclusive excerpts from Britney Spears\\' explosive new memoir, \"The Woman in Me,\" and details from a recent interview and cover shoot with the pop superstar.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e6f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 25/25 [00:00<00:00, 3412.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Practice storing data\n",
    "\n",
    "type(df)\n",
    "\n",
    "df.save_to_disk(\"test_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f2f239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uuid': '2f7aae04-dec6-428a-b0fd-c87a5e16b102',\n",
       " 'title': 'Cowboys and safety Malik Hooker agree on a $24 million, 3-year contract extension',\n",
       " 'date_publish': '2023-08-05 17:02:33',\n",
       " 'source_domain': 'apnews.com',\n",
       " 'url': 'https://apnews.com/article/cowboys-malik-hooker-contract-5531a25a7aecda62883756a7270dfc89',\n",
       " 'political_leaning': 'left_lean',\n",
       " 'text-topic': 'Sports',\n",
       " 'text-topic-exp': 'The article discusses a sports-related event, specifically a contract extension in American Football (NFL) between the Dallas Cowboys and Malik Hooker.',\n",
       " 'text-entity-name': 'Malik Hooker',\n",
       " 'text-entity-sentiment': 'positive',\n",
       " 'text-entity-sentiment-exp': 'He has been healthy since joining Dallas, played a significant number of games in the past two seasons, and tied for second on the club with three interceptions last season',\n",
       " 'text-generic-frame': \"['Economic', 'Capacity and resources', 'Crime and punishment', 'Quality of life']\",\n",
       " 'text-generic-frame-exp': \"The article discusses the financial implications of the contract extension for Malik Hooker (Economic). It also mentions the availability of resources, in this case, the players' health and their ability to play games (Capacity and resources). The comparison of Hooker's interceptions with Trevon Diggs implies a discussion on crime and punishment in the context of football performance (Crime and punishment). Lastly, the article mentions the quality of life for the Cowboys team, specifically their improvement in the safety position (Quality of life).\",\n",
       " 'text-issue-frame': 'Sports Success Story',\n",
       " 'text-issue-frame-exp': \"The article focuses on the contract extension of Malik Hooker, a football player, and his successful performance with the Dallas Cowboys after a challenging start with the Indianapolis Colts. The framing as a 'Sports Success Story' highlights Hooker's personal growth, improvement, and achievement in his career.\",\n",
       " 'img-generic-frame': \"['Cultural identity', 'None']\",\n",
       " 'img-frame-exp': 'The image shows football players in action, wearing team jerseys, which highlights cultural identity through sports. However, there are no specific elements indicating other frames.',\n",
       " 'img-entity-name': 'Dallas Cowboys',\n",
       " 'img-entity-sentiment': 'positive',\n",
       " 'img-entity-sentiment-exp': 'The players are celebrating with one player holding the football and making a positive gesture with his hand.',\n",
       " 'gpt-topic': 'Sports',\n",
       " 'article_text': 'OXNARD, Calif. (AP) — The Dallas Cowboys and safety Malik Hooker agreed Saturday on a $24 million, three-year contract extension.\\nHooker was entering the final year of a two-year contract he signed with the Cowboys after a disappointing four-year career with Indianapolis, which drafted him 15th overall in 2017.\\nHooker’s time with the Colts was marred by injuries, but he has stayed healthy since joining Dallas. Hooker has played 31 games over the past two seasons after being limited to 36 games with the Colts.\\nThe 27-year-old tied Trevon Diggs for second on the club with three interceptions last season. Diggs, who led the NFL and tied a team record with 11 interceptions in 2021, just signed a $97 million extension.\\nHooker, Donovan Wilson and Jayron Kearse have teamed to give the Cowboys their best group of safeties in years. Wilson is expected to miss most of training camp after straining a calf in the first practice.\\n___'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Practice loading from disk\n",
    "# all within the datasets library\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# use the load from disk function\n",
    "df_loaded = load_from_disk(\"test_results\")\n",
    "\n",
    "df_loaded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e6f6a",
   "metadata": {},
   "source": [
    "#### Practice script generation for hydration script\n",
    "\n",
    "Since there's 400,000 plus rows, need to be efficient.\n",
    "\n",
    "Appears that the CLI mode is the best way to use Newsplease to hydrate the dataset. \n",
    "\n",
    "https://github.com/fhamborg/news-please/tree/master\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7faca40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478856"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba3dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../urls_to_crawl.txt\", \"w\") as f:\n",
    "    for url in data['url']:\n",
    "        f.write(f\"{url}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d9e36",
   "metadata": {},
   "source": [
    "## Tokenize and encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0b09d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Column"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['article_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d814d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uuid': '8cdfd2d3-ff6a-475d-b9e0-baefbc8955b8',\n",
       " 'title': 'Mets better be right about being ‘capable of better’',\n",
       " 'date_publish': '2023-06-06 01:15:07',\n",
       " 'source_domain': 'nypost.com',\n",
       " 'url': 'https://nypost.com/2023/06/05/mets-better-be-right-about-them-being-capable-of-better/',\n",
       " 'political_leaning': 'right_lean',\n",
       " 'text-topic': 'MLB (New York Mets Performance)',\n",
       " 'text-topic-exp': \"The article discusses the performance of the New York Mets in Major League Baseball, their current record, run differential, and individual player performances. It also mentions the team's owner's response to a fan's request to acquire Shohei Ohtani, a current MLB player. The focus is primarily on the Mets' on-field performance and their potential for improvement.\",\n",
       " 'text-entity-name': 'Steve Cohen',\n",
       " 'text-entity-sentiment': 'neutral',\n",
       " 'text-entity-sentiment-exp': 'The article portrays Steve Cohen as a businessman focused on the current issues of his team, the Mets, and not actively pursuing other players like Shohei Ohtani. There is no clear indication of a positive or negative sentiment towards him.',\n",
       " 'text-generic-frame': \"['Economic', 'Quality of life', 'Policy prescription and evaluation', 'Crime and punishment', 'Public Opinion', 'Political']\",\n",
       " 'text-generic-frame-exp': \"The article discusses the financial implications of the Mets' performance (Economic, Quality of life), the team's focus on specific policies (Policy prescription and evaluation) to improve their performance, the fans' criticism and booing of the players (Crime and punishment, Public Opinion), and the political implications of the team's high payroll and performance (Political).\",\n",
       " 'text-issue-frame': 'Underperforming Athletes',\n",
       " 'text-issue-frame-exp': \"The article focuses on the poor performance of the Mets team, specifically their low run differential, struggles with hitting, and individual player slumps. The author criticizes the team's performance and suggests that they are capable of better. This framing positions the Mets as underperforming and in need of improvement, which can evoke a sense of urgency and expectation for change among readers.\",\n",
       " 'img-generic-frame': \"['Cultural identity', 'None']\",\n",
       " 'img-frame-exp': 'The image primarily features baseball players and coaches in action, wearing team uniforms, which highlights the cultural identity of the sport and the team. There is no visible indication of any other specific frames such as policy, health and safety, or political issues.',\n",
       " 'img-entity-name': 'New York Mets',\n",
       " 'img-entity-sentiment': 'positive',\n",
       " 'img-entity-sentiment-exp': 'The image shows players in action, celebrating, and coaches observing, which suggests a positive and dynamic atmosphere typical of a successful sports team.',\n",
       " 'gpt-topic': 'Sports',\n",
       " 'article_text': 'A fan leaned over the first base dugout the other day to yell to Mets owner Steve Cohen.\\n“Get Ohtani,” said the fan, likely out of desperation.\\nCohen answered quickly and good-naturedly, “Who’s he?”\\nA few moments later Cohen explained to The Post that he and the Mets are concentrating on more current issues. There are presumably two reasons for this: 1) It helps them stay within baseball rules disallowing tampering with other teams’ stars, and 2) there’s plenty to try to correct right there in front of them.\\nLater in that pregame conversation, Cohen noted with a smile — and perhaps slightly sarcastically, at least I hope it was sarcasm — that they were two games over .500. (This was before two more defeats dropped them to an even .500.)\\nAnd lest anyone who hasn’t been paying close attention thinks that’s a fluke, please note that they tote a negative-12 run differential. So yes, they are fortunate to be .500.\\nThey are also lucky to be in the National League, which is playing like the senior circuit (as in very old) and allowing the eminently average to contend. Two games separate the Mets from a playoff spot following their sweep at the hands of the Blue Jays, fourth-place denizens of the AL East.\\nMets manager Buck Showalter said, rather hopefully, following Sunday’s defeat, “We are capable of better.” (If you study the transcription of Showalter speak, you will indeed find some pearls in the word salad, and I’d rate this as one.)\\nPerhaps we shall soon find out if it’s true. Among their next five opponents — starting Tuesday at the first-place Braves, their noted nemesis — are four winning teams plus the St. Louis Cardinals, who are one of maybe five teams as or more disappointing than the Mets (the Padres, Phillies, White Sox and Mariners may qualify as well).\\nI do think there’s a chance Buck’s right (he usually is, except when pitching to Vladimir Guerrero Jr.). Anyway, here’s a little bit of evidence the Mets are capable of better. Or at least that they have to be: If one were to hand out grades to all the Mets, the only one who’d get a solid, no-questions-asked A is closer David Robertson, who, as we know, was sadly pressed into that role when Edwin Diaz went down celebrating before the season even began.\\nRobertson really has been perfect* (I don’t count pitching to Guerrero Saturday, as he should have been ordered to walk him), and everyone else has been something less.\\nThe fans are starting to notice, as the booing has migrated beyond poor Daniel Vogelbach, who never deserved the brunt of their ire (he’s paid $1.5 million, which is practically volunteer work by big-league standards). They’ve even hit lately on Francisco Lindor, the $341 million man, whose glove is apparently the most valuable one in baseball (Showalter mentioned he’s been good defensively, which really isn’t much of a defense for a man with a $34.1M annual salary.)\\nReally, you can’t blame Lindor entirely. He is overworked, especially with the team’s only true backup shortstop, Luis Guillorme in Triple-A. The only reason I can figure Guillorme was demoted is because they must have too many good players. But we know that can’t be the case, or they wouldn’t be out of the playoff picture while the small-market Pirates and the smaller-revenue Marlins are in.\\nIt’s only right fans are starting to catch on that this isn’t all on Vogelbach, though he does need to lift the ball more (and that .315 slugging percentage) to fit his job description as designated hitter. He may not even be around forever, as more good players are on the way — Omar Narvaez, the original starting catcher, should be activated Tuesday — so it’s only smart that fans have started in on some real culprits.\\nLindor’s average is .214, he has whiffed eight times in his last 12 at-bats and he may need a day off (though it’s hard to see that happening against the hated Braves).\\nStarling Marte is still toting a below-average .314 on-base percentage, which is a shame since the new rules allow him to steal at will (17 of 20 so far).\\nThe best thing about Jeff McNeil’s appearances lately is his walk-up music (Def Leppard, he is apparently an old soul). Anyway, Joel Sherman pointed out that he has one extra-base hit in his last 31 games.\\nEven Pete Alonso, who isn’t far off his goal of a 60-homer pace (he’s at 56.7 at last count), is slumping.\\nOverall, the Mets are 22nd in OPS at .713, which can’t entirely be Vogelbach’s fault. Also, they rarely get a hit with runners in scoring position (0-for-19 vs. the Jays).\\nAt these prices — a record $377M payroll — it’s a wonder Cohen maintains his good humor. Things look so bad now, maybe even Ohtani couldn’t make a difference.\\nTruthfully, the big thing that is keeping them going now is their belief, as Buck said, that they are capable of better. Let’s hope, with 100-plus games to go, that is really the case.',\n",
       " 'input_ids': [101,\n",
       "  1037,\n",
       "  5470,\n",
       "  4016,\n",
       "  2058,\n",
       "  1996,\n",
       "  2034,\n",
       "  2918,\n",
       "  8655,\n",
       "  5833,\n",
       "  1996,\n",
       "  2060,\n",
       "  2154,\n",
       "  2000,\n",
       "  14315,\n",
       "  2000,\n",
       "  15253,\n",
       "  3954,\n",
       "  3889,\n",
       "  9946,\n",
       "  1012,\n",
       "  1523,\n",
       "  2131,\n",
       "  2821,\n",
       "  17681,\n",
       "  1010,\n",
       "  1524,\n",
       "  2056,\n",
       "  1996,\n",
       "  5470,\n",
       "  1010,\n",
       "  3497,\n",
       "  2041,\n",
       "  1997,\n",
       "  15561,\n",
       "  1012,\n",
       "  9946,\n",
       "  4660,\n",
       "  2855,\n",
       "  1998,\n",
       "  2204,\n",
       "  1011,\n",
       "  3267,\n",
       "  18718,\n",
       "  1010,\n",
       "  1523,\n",
       "  2040,\n",
       "  1521,\n",
       "  1055,\n",
       "  2002,\n",
       "  1029,\n",
       "  1524,\n",
       "  1037,\n",
       "  2261,\n",
       "  5312,\n",
       "  2101,\n",
       "  9946,\n",
       "  4541,\n",
       "  2000,\n",
       "  1996,\n",
       "  2695,\n",
       "  2008,\n",
       "  2002,\n",
       "  1998,\n",
       "  1996,\n",
       "  15253,\n",
       "  2024,\n",
       "  16966,\n",
       "  2006,\n",
       "  2062,\n",
       "  2783,\n",
       "  3314,\n",
       "  1012,\n",
       "  2045,\n",
       "  2024,\n",
       "  10712,\n",
       "  2048,\n",
       "  4436,\n",
       "  2005,\n",
       "  2023,\n",
       "  1024,\n",
       "  1015,\n",
       "  1007,\n",
       "  2009,\n",
       "  7126,\n",
       "  2068,\n",
       "  2994,\n",
       "  2306,\n",
       "  3598,\n",
       "  3513,\n",
       "  4487,\n",
       "  12002,\n",
       "  8261,\n",
       "  2075,\n",
       "  17214,\n",
       "  4842,\n",
       "  2075,\n",
       "  2007,\n",
       "  2060,\n",
       "  2780,\n",
       "  1521,\n",
       "  3340,\n",
       "  1010,\n",
       "  1998,\n",
       "  1016,\n",
       "  1007,\n",
       "  2045,\n",
       "  1521,\n",
       "  1055,\n",
       "  7564,\n",
       "  2000,\n",
       "  3046,\n",
       "  2000,\n",
       "  6149,\n",
       "  2157,\n",
       "  2045,\n",
       "  1999,\n",
       "  2392,\n",
       "  1997,\n",
       "  2068,\n",
       "  1012,\n",
       "  2101,\n",
       "  1999,\n",
       "  2008,\n",
       "  3653,\n",
       "  16650,\n",
       "  4512,\n",
       "  1010,\n",
       "  9946,\n",
       "  3264,\n",
       "  2007,\n",
       "  1037,\n",
       "  2868,\n",
       "  1517,\n",
       "  1998,\n",
       "  3383,\n",
       "  3621,\n",
       "  23800,\n",
       "  1010,\n",
       "  2012,\n",
       "  2560,\n",
       "  1045,\n",
       "  3246,\n",
       "  2009,\n",
       "  2001,\n",
       "  20954,\n",
       "  1517,\n",
       "  2008,\n",
       "  2027,\n",
       "  2020,\n",
       "  2048,\n",
       "  2399,\n",
       "  2058,\n",
       "  1012,\n",
       "  3156,\n",
       "  1012,\n",
       "  1006,\n",
       "  2023,\n",
       "  2001,\n",
       "  2077,\n",
       "  2048,\n",
       "  2062,\n",
       "  14222,\n",
       "  3333,\n",
       "  2068,\n",
       "  2000,\n",
       "  2019,\n",
       "  2130,\n",
       "  1012,\n",
       "  3156,\n",
       "  1012,\n",
       "  1007,\n",
       "  1998,\n",
       "  26693,\n",
       "  3087,\n",
       "  2040,\n",
       "  8440,\n",
       "  1521,\n",
       "  1056,\n",
       "  2042,\n",
       "  7079,\n",
       "  2485,\n",
       "  3086,\n",
       "  6732,\n",
       "  2008,\n",
       "  1521,\n",
       "  1055,\n",
       "  1037,\n",
       "  19857,\n",
       "  3489,\n",
       "  1010,\n",
       "  3531,\n",
       "  3602,\n",
       "  2008,\n",
       "  2027,\n",
       "  2000,\n",
       "  2618,\n",
       "  1037,\n",
       "  4997,\n",
       "  1011,\n",
       "  2260,\n",
       "  2448,\n",
       "  11658,\n",
       "  1012,\n",
       "  2061,\n",
       "  2748,\n",
       "  1010,\n",
       "  2027,\n",
       "  2024,\n",
       "  19590,\n",
       "  2000,\n",
       "  2022,\n",
       "  1012,\n",
       "  3156,\n",
       "  1012,\n",
       "  2027,\n",
       "  2024,\n",
       "  2036,\n",
       "  5341,\n",
       "  2000,\n",
       "  2022,\n",
       "  1999,\n",
       "  1996,\n",
       "  2120,\n",
       "  2223,\n",
       "  1010,\n",
       "  2029,\n",
       "  2003,\n",
       "  2652,\n",
       "  2066,\n",
       "  1996,\n",
       "  3026,\n",
       "  4984,\n",
       "  1006,\n",
       "  2004,\n",
       "  1999,\n",
       "  2200,\n",
       "  2214,\n",
       "  1007,\n",
       "  1998,\n",
       "  4352,\n",
       "  1996,\n",
       "  14953,\n",
       "  2135,\n",
       "  2779,\n",
       "  2000,\n",
       "  27481,\n",
       "  1012,\n",
       "  2048,\n",
       "  2399,\n",
       "  3584,\n",
       "  1996,\n",
       "  15253,\n",
       "  2013,\n",
       "  1037,\n",
       "  7808,\n",
       "  3962,\n",
       "  2206,\n",
       "  2037,\n",
       "  11740,\n",
       "  2012,\n",
       "  1996,\n",
       "  2398,\n",
       "  1997,\n",
       "  1996,\n",
       "  2630,\n",
       "  18930,\n",
       "  1010,\n",
       "  2959,\n",
       "  1011,\n",
       "  2173,\n",
       "  7939,\n",
       "  4697,\n",
       "  3619,\n",
       "  1997,\n",
       "  1996,\n",
       "  2632,\n",
       "  2264,\n",
       "  1012,\n",
       "  15253,\n",
       "  3208,\n",
       "  10131,\n",
       "  2265,\n",
       "  2389,\n",
       "  3334,\n",
       "  2056,\n",
       "  1010,\n",
       "  2738,\n",
       "  11504,\n",
       "  1010,\n",
       "  2206,\n",
       "  4465,\n",
       "  1521,\n",
       "  1055,\n",
       "  4154,\n",
       "  1010,\n",
       "  1523,\n",
       "  2057,\n",
       "  2024,\n",
       "  5214,\n",
       "  1997,\n",
       "  2488,\n",
       "  1012,\n",
       "  1524,\n",
       "  1006,\n",
       "  2065,\n",
       "  2017,\n",
       "  2817,\n",
       "  1996,\n",
       "  14193,\n",
       "  1997,\n",
       "  2265,\n",
       "  2389,\n",
       "  3334,\n",
       "  3713,\n",
       "  1010,\n",
       "  2017,\n",
       "  2097,\n",
       "  5262,\n",
       "  2424,\n",
       "  2070,\n",
       "  21944,\n",
       "  1999,\n",
       "  1996,\n",
       "  2773,\n",
       "  16521,\n",
       "  1010,\n",
       "  1998,\n",
       "  1045,\n",
       "  1521,\n",
       "  1040,\n",
       "  3446,\n",
       "  2023,\n",
       "  2004,\n",
       "  2028,\n",
       "  1012,\n",
       "  1007,\n",
       "  3383,\n",
       "  2057,\n",
       "  4618,\n",
       "  2574,\n",
       "  2424,\n",
       "  2041,\n",
       "  2065,\n",
       "  2009,\n",
       "  1521,\n",
       "  1055,\n",
       "  2995,\n",
       "  1012,\n",
       "  2426,\n",
       "  2037,\n",
       "  2279,\n",
       "  2274,\n",
       "  7892,\n",
       "  1517,\n",
       "  3225,\n",
       "  9857,\n",
       "  2012,\n",
       "  1996,\n",
       "  2034,\n",
       "  1011,\n",
       "  2173,\n",
       "  13980,\n",
       "  1010,\n",
       "  2037,\n",
       "  3264,\n",
       "  21363,\n",
       "  1517,\n",
       "  2024,\n",
       "  2176,\n",
       "  3045,\n",
       "  2780,\n",
       "  4606,\n",
       "  1996,\n",
       "  2358,\n",
       "  1012,\n",
       "  3434,\n",
       "  9310,\n",
       "  1010,\n",
       "  2040,\n",
       "  2024,\n",
       "  2028,\n",
       "  1997,\n",
       "  2672,\n",
       "  2274,\n",
       "  2780,\n",
       "  2004,\n",
       "  2030,\n",
       "  2062,\n",
       "  15640,\n",
       "  2084,\n",
       "  1996,\n",
       "  15253,\n",
       "  1006,\n",
       "  1996,\n",
       "  21577,\n",
       "  1010,\n",
       "  15711,\n",
       "  1010,\n",
       "  2317,\n",
       "  9175,\n",
       "  1998,\n",
       "  18049,\n",
       "  2089,\n",
       "  7515,\n",
       "  2004,\n",
       "  2092,\n",
       "  1007,\n",
       "  1012,\n",
       "  1045,\n",
       "  2079,\n",
       "  2228,\n",
       "  2045,\n",
       "  1521,\n",
       "  1055,\n",
       "  1037,\n",
       "  3382,\n",
       "  10131,\n",
       "  1521,\n",
       "  1055,\n",
       "  2157,\n",
       "  1006,\n",
       "  2002,\n",
       "  2788,\n",
       "  2003,\n",
       "  1010,\n",
       "  3272,\n",
       "  2043,\n",
       "  14696,\n",
       "  2000,\n",
       "  8748,\n",
       "  16938,\n",
       "  3781,\n",
       "  1012,\n",
       "  1007,\n",
       "  1012,\n",
       "  4312,\n",
       "  1010,\n",
       "  2182,\n",
       "  1521,\n",
       "  1055,\n",
       "  1037,\n",
       "  2210,\n",
       "  2978,\n",
       "  1997,\n",
       "  3350,\n",
       "  1996,\n",
       "  15253,\n",
       "  2024,\n",
       "  5214,\n",
       "  1997,\n",
       "  2488,\n",
       "  1012,\n",
       "  2030,\n",
       "  2012,\n",
       "  2560,\n",
       "  2008,\n",
       "  2027,\n",
       "  2031,\n",
       "  2000,\n",
       "  2022,\n",
       "  1024,\n",
       "  2065,\n",
       "  2028,\n",
       "  2020,\n",
       "  2000,\n",
       "  2192,\n",
       "  2041,\n",
       "  7022,\n",
       "  2000,\n",
       "  2035,\n",
       "  1996,\n",
       "  15253,\n",
       "  1010,\n",
       "  1996,\n",
       "  2069,\n",
       "  2028,\n",
       "  2040,\n",
       "  1521,\n",
       "  1040,\n",
       "  2131,\n",
       "  1037,\n",
       "  5024,\n",
       "  1010,\n",
       "  2053,\n",
       "  1011,\n",
       "  3980,\n",
       "  1011,\n",
       "  2356,\n",
       "  1037,\n",
       "  2003,\n",
       "  3553,\n",
       "  2585,\n",
       "  9923,\n",
       "  1010,\n",
       "  2040,\n",
       "  1010,\n",
       "  2004,\n",
       "  2057,\n",
       "  2113,\n",
       "  1010,\n",
       "  2001,\n",
       "  13718,\n",
       "  4508,\n",
       "  2046,\n",
       "  2008,\n",
       "  2535,\n",
       "  2043,\n",
       "  10049,\n",
       "  12526,\n",
       "  2253,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the default auto tokenizer \n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Pick a test model checkpoint, change this later if desired\n",
    "model = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, local_files_only=False)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"article_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "tokenized_df = df.map(tokenize_function, batched=True)\n",
    "tokenized_df[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51966b",
   "metadata": {},
   "source": [
    "## Set Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b53258e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['uuid', 'title', 'date_publish', 'source_domain', 'url', 'political_leaning', 'text-topic', 'text-topic-exp', 'text-entity-name', 'text-entity-sentiment', 'text-entity-sentiment-exp', 'text-generic-frame', 'text-generic-frame-exp', 'text-issue-frame', 'text-issue-frame-exp', 'img-generic-frame', 'img-frame-exp', 'img-entity-name', 'img-entity-sentiment', 'img-entity-sentiment-exp', 'gpt-topic', 'article_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 25\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c68943df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'torch',\n",
       " 'format_kwargs': {},\n",
       " 'columns': ['input_ids', 'token_type_ids', 'attention_mask', 'text-topic'],\n",
       " 'output_all_columns': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set format doesn't delete the other columns, it just hides them. can toggle back to see them\n",
    "tokenized_df.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=['input_ids', 'token_type_ids', 'attention_mask', \"text-topic\"]\n",
    ")\n",
    "tokenized_df.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eb3281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': None,\n",
       " 'format_kwargs': {},\n",
       " 'columns': ['uuid',\n",
       "  'title',\n",
       "  'date_publish',\n",
       "  'source_domain',\n",
       "  'url',\n",
       "  'political_leaning',\n",
       "  'text-topic',\n",
       "  'text-topic-exp',\n",
       "  'text-entity-name',\n",
       "  'text-entity-sentiment',\n",
       "  'text-entity-sentiment-exp',\n",
       "  'text-generic-frame',\n",
       "  'text-generic-frame-exp',\n",
       "  'text-issue-frame',\n",
       "  'text-issue-frame-exp',\n",
       "  'img-generic-frame',\n",
       "  'img-frame-exp',\n",
       "  'img-entity-name',\n",
       "  'img-entity-sentiment',\n",
       "  'img-entity-sentiment-exp',\n",
       "  'gpt-topic',\n",
       "  'article_text',\n",
       "  'input_ids',\n",
       "  'token_type_ids',\n",
       "  'attention_mask'],\n",
       " 'output_all_columns': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toggling back to see the hidden columns\n",
    "tokenized_df.reset_format()\n",
    "tokenized_df.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59fbc6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=['input_ids', 'token_type_ids', 'attention_mask', \"text-topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7da482",
   "metadata": {},
   "source": [
    "## Creating the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f329a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create the conveyor belt\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_df,\n",
    "    shuffle = True, # mixes the data so the model doesn't learn the order\n",
    "    batch_size = 4 # number of articles to process at once\n",
    ")\n",
    "\n",
    "# in the above, the model sees 16 rows at once, each with 128 numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41788504",
   "metadata": {},
   "source": [
    "## Run sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10dd8c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Batch 0 ---\n",
      "Input IDs shape: torch.Size([4, 512])\n",
      "Attention Mask shape: torch.Size([4, 512])\n",
      "Labels in this batch: ['Gender-Affirming Health Services in Schools', 'Bank Tax Proposal in Italy', 'Abortion Pill Access', 'Tech']\n",
      "First 10 tokens decoded: [CLS] the health clinic that has black panther party roots\n",
      "\n",
      "\n",
      "--- Batch 1 ---\n",
      "Input IDs shape: torch.Size([4, 512])\n",
      "Attention Mask shape: torch.Size([4, 512])\n",
      "Labels in this batch: ['Accident', 'Baseball Transfers', 'Drag Worship Service Controversy', 'Politics']\n",
      "First 10 tokens decoded: [CLS] miami - a miami - dade police officer had\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll just look at the first 2 batches to make sure it works\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i >= 2: \n",
    "        break\n",
    "        \n",
    "    print(f\"--- Batch {i} ---\")\n",
    "    print(f\"Input IDs shape: {batch['input_ids'].shape}\")\n",
    "    print(f\"Attention Mask shape: {batch['attention_mask'].shape}\")\n",
    "    print(f\"Labels in this batch: {batch['text-topic']}\")\n",
    "    \n",
    "    # If you want to see what the model \"sees\" (first 10 tokens of first row)\n",
    "    # This turns those IDs back into words!\n",
    "    # USE tokenizer.decode for specific debugging\n",
    "    example_text = tokenizer.decode(batch['input_ids'][0][:10])\n",
    "    print(f\"First 10 tokens decoded: {example_text}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b5019",
   "metadata": {},
   "source": [
    "# Let's run a test model on a small subset of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d5bf26",
   "metadata": {},
   "source": [
    "### testing data connection for hydrated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3acb9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstly let's load in our hydrated dataset\n",
    "import psycopg2\n",
    "\n",
    "# create a connection object\n",
    "conn = psycopg2.connect(\n",
    "    dbname=os.getenv(\"DB_NAME\"),\n",
    "    user=os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7096bbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(361975,)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a simple query\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT COUNT(*) \n",
    "            FROM newsarticles;\"\"\")\n",
    "result = cur.fetchall()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f47c4007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhrou\\AppData\\Local\\Temp\\ipykernel_280420\\2839042975.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT COUNT(*) FROM newsarticles\",\n"
     ]
    }
   ],
   "source": [
    "# Load query into pandas\n",
    "import pandas as pd\n",
    "df = pd.read_sql(\"SELECT COUNT(*) FROM newsarticles\",\n",
    "                 conn)\n",
    "df.head()\n",
    "conn.close()\n",
    "cur.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0283529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS CLOSE CONNECTIONS\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48ac7d",
   "metadata": {},
   "source": [
    "### Create a small hydrated data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66fda887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datasets.arrow_dataset.Dataset, 478856)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's just learn to play around with the arrow_dataset\n",
    "type(data), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eebf3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uuid',\n",
       " 'title',\n",
       " 'date_publish',\n",
       " 'source_domain',\n",
       " 'url',\n",
       " 'political_leaning',\n",
       " 'text-topic',\n",
       " 'text-topic-exp',\n",
       " 'text-entity-name',\n",
       " 'text-entity-sentiment',\n",
       " 'text-entity-sentiment-exp',\n",
       " 'text-generic-frame',\n",
       " 'text-generic-frame-exp',\n",
       " 'text-issue-frame',\n",
       " 'text-issue-frame-exp',\n",
       " 'img-generic-frame',\n",
       " 'img-frame-exp',\n",
       " 'img-entity-name',\n",
       " 'img-entity-sentiment',\n",
       " 'img-entity-sentiment-exp',\n",
       " 'gpt-topic']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7ef5638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>title</th>\n",
       "      <th>date_publish</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>url</th>\n",
       "      <th>political_leaning</th>\n",
       "      <th>text-topic</th>\n",
       "      <th>text-topic-exp</th>\n",
       "      <th>text-entity-name</th>\n",
       "      <th>text-entity-sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>text-generic-frame</th>\n",
       "      <th>text-generic-frame-exp</th>\n",
       "      <th>text-issue-frame</th>\n",
       "      <th>text-issue-frame-exp</th>\n",
       "      <th>img-generic-frame</th>\n",
       "      <th>img-frame-exp</th>\n",
       "      <th>img-entity-name</th>\n",
       "      <th>img-entity-sentiment</th>\n",
       "      <th>img-entity-sentiment-exp</th>\n",
       "      <th>gpt-topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2de4efd-6ed0-4a0d-99e3-51a8c79e2b3e</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-19 16:58:00</td>\n",
       "      <td>www.cbsnews.com</td>\n",
       "      <td>https://www.cbsnews.com/news/trump-suing-abc-n...</td>\n",
       "      <td>left_lean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>['Political']</td>\n",
       "      <td>The image features two prominent political fig...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The image shows Donald Trump in a formal setti...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f7aae04-dec6-428a-b0fd-c87a5e16b102</td>\n",
       "      <td>Cowboys and safety Malik Hooker agree on a $24...</td>\n",
       "      <td>2023-08-05 17:02:33</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>https://apnews.com/article/cowboys-malik-hooke...</td>\n",
       "      <td>left_lean</td>\n",
       "      <td>Sports</td>\n",
       "      <td>The article discusses a sports-related event, ...</td>\n",
       "      <td>Malik Hooker</td>\n",
       "      <td>positive</td>\n",
       "      <td>...</td>\n",
       "      <td>['Economic', 'Capacity and resources', 'Crime ...</td>\n",
       "      <td>The article discusses the financial implicatio...</td>\n",
       "      <td>Sports Success Story</td>\n",
       "      <td>The article focuses on the contract extension ...</td>\n",
       "      <td>['Cultural identity', 'None']</td>\n",
       "      <td>The image shows football players in action, we...</td>\n",
       "      <td>Dallas Cowboys</td>\n",
       "      <td>positive</td>\n",
       "      <td>The players are celebrating with one player ho...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fef978c8-f085-4871-9d6f-0fe4409148f7</td>\n",
       "      <td>KCAL News Anchor Rudabeh Shahbazi speaks at Ir...</td>\n",
       "      <td>2024-03-04 07:15:00</td>\n",
       "      <td>www.cbsnews.com</td>\n",
       "      <td>https://www.cbsnews.com/losangeles/video/kcal-...</td>\n",
       "      <td>left_lean</td>\n",
       "      <td>Iranian American Women</td>\n",
       "      <td>The article is about KCAL News anchor Rudabeh ...</td>\n",
       "      <td>Rudabeh Shahbazi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>...</td>\n",
       "      <td>['Cultural identity', 'Public Opinion']</td>\n",
       "      <td>The article discusses an event organized by th...</td>\n",
       "      <td>Empowerment of Women</td>\n",
       "      <td>The article focuses on a conference for Irania...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8cdfd2d3-ff6a-475d-b9e0-baefbc8955b8</td>\n",
       "      <td>Mets better be right about being ‘capable of b...</td>\n",
       "      <td>2023-06-06 01:15:07</td>\n",
       "      <td>nypost.com</td>\n",
       "      <td>https://nypost.com/2023/06/05/mets-better-be-r...</td>\n",
       "      <td>right_lean</td>\n",
       "      <td>MLB (New York Mets Performance)</td>\n",
       "      <td>The article discusses the performance of the N...</td>\n",
       "      <td>Steve Cohen</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>['Economic', 'Quality of life', 'Policy prescr...</td>\n",
       "      <td>The article discusses the financial implicatio...</td>\n",
       "      <td>Underperforming Athletes</td>\n",
       "      <td>The article focuses on the poor performance of...</td>\n",
       "      <td>['Cultural identity', 'None']</td>\n",
       "      <td>The image primarily features baseball players ...</td>\n",
       "      <td>New York Mets</td>\n",
       "      <td>positive</td>\n",
       "      <td>The image shows players in action, celebrating...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>af3378b7-447e-44e7-8c1f-1f752ecc5539</td>\n",
       "      <td>QBs Watson, Howell have solid starts, Brissett...</td>\n",
       "      <td>2023-08-12 03:53:58</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>https://apnews.com/article/browns-commanders-d...</td>\n",
       "      <td>left_lean</td>\n",
       "      <td>NFL Preseason Game</td>\n",
       "      <td>The article discusses an NFL preseason game be...</td>\n",
       "      <td>Deshaun Watson</td>\n",
       "      <td>positive</td>\n",
       "      <td>...</td>\n",
       "      <td>['Economic', 'Quality of life', 'Legality, con...</td>\n",
       "      <td>The article discusses the financial investment...</td>\n",
       "      <td>Redemption Narrative</td>\n",
       "      <td>The article focuses on Deshaun Watson's return...</td>\n",
       "      <td>['None']</td>\n",
       "      <td>The image depicts a football player in action,...</td>\n",
       "      <td>Deshaun Watson</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The image shows Deshaun Watson in action durin...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid  \\\n",
       "0  f2de4efd-6ed0-4a0d-99e3-51a8c79e2b3e   \n",
       "1  2f7aae04-dec6-428a-b0fd-c87a5e16b102   \n",
       "2  fef978c8-f085-4871-9d6f-0fe4409148f7   \n",
       "3  8cdfd2d3-ff6a-475d-b9e0-baefbc8955b8   \n",
       "4  af3378b7-447e-44e7-8c1f-1f752ecc5539   \n",
       "\n",
       "                                               title         date_publish  \\\n",
       "0                                               None  2024-03-19 16:58:00   \n",
       "1  Cowboys and safety Malik Hooker agree on a $24...  2023-08-05 17:02:33   \n",
       "2  KCAL News Anchor Rudabeh Shahbazi speaks at Ir...  2024-03-04 07:15:00   \n",
       "3  Mets better be right about being ‘capable of b...  2023-06-06 01:15:07   \n",
       "4  QBs Watson, Howell have solid starts, Brissett...  2023-08-12 03:53:58   \n",
       "\n",
       "     source_domain                                                url  \\\n",
       "0  www.cbsnews.com  https://www.cbsnews.com/news/trump-suing-abc-n...   \n",
       "1       apnews.com  https://apnews.com/article/cowboys-malik-hooke...   \n",
       "2  www.cbsnews.com  https://www.cbsnews.com/losangeles/video/kcal-...   \n",
       "3       nypost.com  https://nypost.com/2023/06/05/mets-better-be-r...   \n",
       "4       apnews.com  https://apnews.com/article/browns-commanders-d...   \n",
       "\n",
       "  political_leaning                       text-topic  \\\n",
       "0         left_lean                             None   \n",
       "1         left_lean                           Sports   \n",
       "2         left_lean           Iranian American Women   \n",
       "3        right_lean  MLB (New York Mets Performance)   \n",
       "4         left_lean               NFL Preseason Game   \n",
       "\n",
       "                                      text-topic-exp  text-entity-name  \\\n",
       "0                                               None              None   \n",
       "1  The article discusses a sports-related event, ...      Malik Hooker   \n",
       "2  The article is about KCAL News anchor Rudabeh ...  Rudabeh Shahbazi   \n",
       "3  The article discusses the performance of the N...       Steve Cohen   \n",
       "4  The article discusses an NFL preseason game be...    Deshaun Watson   \n",
       "\n",
       "  text-entity-sentiment  ...  \\\n",
       "0                  None  ...   \n",
       "1              positive  ...   \n",
       "2              Positive  ...   \n",
       "3               neutral  ...   \n",
       "4              positive  ...   \n",
       "\n",
       "                                  text-generic-frame  \\\n",
       "0                                               None   \n",
       "1  ['Economic', 'Capacity and resources', 'Crime ...   \n",
       "2            ['Cultural identity', 'Public Opinion']   \n",
       "3  ['Economic', 'Quality of life', 'Policy prescr...   \n",
       "4  ['Economic', 'Quality of life', 'Legality, con...   \n",
       "\n",
       "                              text-generic-frame-exp  \\\n",
       "0                                               None   \n",
       "1  The article discusses the financial implicatio...   \n",
       "2  The article discusses an event organized by th...   \n",
       "3  The article discusses the financial implicatio...   \n",
       "4  The article discusses the financial investment...   \n",
       "\n",
       "           text-issue-frame  \\\n",
       "0                      None   \n",
       "1      Sports Success Story   \n",
       "2      Empowerment of Women   \n",
       "3  Underperforming Athletes   \n",
       "4      Redemption Narrative   \n",
       "\n",
       "                                text-issue-frame-exp  \\\n",
       "0                                               None   \n",
       "1  The article focuses on the contract extension ...   \n",
       "2  The article focuses on a conference for Irania...   \n",
       "3  The article focuses on the poor performance of...   \n",
       "4  The article focuses on Deshaun Watson's return...   \n",
       "\n",
       "               img-generic-frame  \\\n",
       "0                  ['Political']   \n",
       "1  ['Cultural identity', 'None']   \n",
       "2                           None   \n",
       "3  ['Cultural identity', 'None']   \n",
       "4                       ['None']   \n",
       "\n",
       "                                       img-frame-exp img-entity-name  \\\n",
       "0  The image features two prominent political fig...    Donald Trump   \n",
       "1  The image shows football players in action, we...  Dallas Cowboys   \n",
       "2                                               None            None   \n",
       "3  The image primarily features baseball players ...   New York Mets   \n",
       "4  The image depicts a football player in action,...  Deshaun Watson   \n",
       "\n",
       "  img-entity-sentiment                           img-entity-sentiment-exp  \\\n",
       "0              neutral  The image shows Donald Trump in a formal setti...   \n",
       "1             positive  The players are celebrating with one player ho...   \n",
       "2                 None                                               None   \n",
       "3             positive  The image shows players in action, celebrating...   \n",
       "4              neutral  The image shows Deshaun Watson in action durin...   \n",
       "\n",
       "  gpt-topic  \n",
       "0      None  \n",
       "1    Sports  \n",
       "2    Social  \n",
       "3    Sports  \n",
       "4    Sports  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.shuffle(seed=42).select(range(1000)).to_pandas()\n",
    "\n",
    "df.head()\n",
    "\n",
    "# then you can do all kinds of EDA on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf734f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,\n",
       " pandas.core.frame.DataFrame,\n",
       " Index(['uuid', 'title', 'date_publish', 'source_domain', 'url',\n",
       "        'political_leaning', 'text-topic', 'text-topic-exp', 'text-entity-name',\n",
       "        'text-entity-sentiment', 'text-entity-sentiment-exp',\n",
       "        'text-generic-frame', 'text-generic-frame-exp', 'text-issue-frame',\n",
       "        'text-issue-frame-exp', 'img-generic-frame', 'img-frame-exp',\n",
       "        'img-entity-name', 'img-entity-sentiment', 'img-entity-sentiment-exp',\n",
       "        'gpt-topic'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# but for now, let's just have our shuffled 2500 sample to train a small model on and merge in from the database\n",
    "data_subset = data.shuffle(seed=42).select(range(2500)).to_pandas() # conversion might not be possible in the full version\n",
    "len(data_subset), type(data_subset), data_subset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eba58485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with the full data\n",
    "data_pd = data.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64bd3f8",
   "metadata": {},
   "source": [
    "### Merging in news articles\n",
    "\n",
    "Next steps:\n",
    "- merge in the news articles\n",
    "\n",
    "the most efficient way to do this is actually to send my table to the database, do the merge on the server, then pull back the result.\n",
    "\n",
    "We can do this with execute_values from psycopg2.extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "783db48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# create a connection object\n",
    "conn = psycopg2.connect(\n",
    "    dbname=os.getenv(\"DB_NAME\"),\n",
    "    user=os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\")\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c4e88ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uuid', 'title', 'date_publish', 'source_domain', 'url',\n",
       "       'political_leaning', 'text-topic', 'text-topic-exp', 'text-entity-name',\n",
       "       'text-entity-sentiment', 'text-entity-sentiment-exp',\n",
       "       'text-generic-frame', 'text-generic-frame-exp', 'text-issue-frame',\n",
       "       'text-issue-frame-exp', 'img-generic-frame', 'img-frame-exp',\n",
       "       'img-entity-name', 'img-entity-sentiment', 'img-entity-sentiment-exp',\n",
       "       'gpt-topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b907ac33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uuid', 'title', 'date_publish', 'source_domain', 'url',\n",
       "       'political_leaning', 'text_topic', 'text_topic_exp', 'text_entity_name',\n",
       "       'text_entity_sentiment', 'text_entity_sentiment_exp',\n",
       "       'text_generic_frame', 'text_generic_frame_exp', 'text_issue_frame',\n",
       "       'text_issue_frame_exp', 'img_generic_frame', 'img_frame_exp',\n",
       "       'img_entity_name', 'img_entity_sentiment', 'img_entity_sentiment_exp',\n",
       "       'gpt_topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sql doesn't like hyphens in column names\n",
    "data_pd.columns = data_pd.columns.str.replace(\"-\",\"_\")\n",
    "data_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ff7c7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'uuid', 'title', 'date_publish', 'source_domain',\n",
       "       'political_leaning', 'text_topic', 'text_topic_exp', 'text_entity_name',\n",
       "       'text_entity_sentiment', 'text_entity_sentiment_exp',\n",
       "       'text_generic_frame', 'text_generic_frame_exp', 'text_issue_frame',\n",
       "       'text_issue_frame_exp', 'img_generic_frame', 'img_frame_exp',\n",
       "       'img_entity_name', 'img_entity_sentiment', 'img_entity_sentiment_exp',\n",
       "       'gpt_topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also need the url as the first column to act as a key\n",
    "cols = ['url'] + [c for c in data_pd.columns if c != 'url']\n",
    "data_pd = data_pd[cols]\n",
    "data_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b226807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this full pipline, this pandas conversion might not be possible\n",
    "cols = list(data_pd.columns)\n",
    "values = [tuple(row) for row in data_pd.itertuples(index=False)] # itertuples is an interable that converts each row into tuplez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a17d9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly we create the table in the database\n",
    "cur.execute(f\"\"\"\n",
    "            CREATE TABLE mm_framing_full (\n",
    "    url TEXT,\n",
    "    uuid TEXT,\n",
    "    title TEXT,\n",
    "    date_publish TEXT,\n",
    "    source_domain TEXT,\n",
    "    political_leaning TEXT,\n",
    "    text_topic TEXT,\n",
    "    text_topic_exp TEXT,\n",
    "    text_entity_name TEXT,\n",
    "    text_entity_sentiment TEXT,\n",
    "    text_entity_sentiment_exp TEXT,\n",
    "    text_generic_frame TEXT,\n",
    "    text_generic_frame_exp TEXT,\n",
    "    text_issue_frame TEXT,\n",
    "    text_issue_frame_exp TEXT,\n",
    "    img_generic_frame TEXT,\n",
    "    img_frame_exp TEXT,\n",
    "    img_entity_name TEXT,\n",
    "    img_entity_sentiment TEXT,\n",
    "    img_entity_sentiment_exp TEXT,\n",
    "    gpt_topic TEXT);\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6893932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "\n",
    "query = f\"\"\"\n",
    "INSERT INTO mm_framing_full ({\",\".join(cols)})\n",
    "\n",
    "    VALUES %s\n",
    "\"\"\"\n",
    "# in the above, the %s takes the value of values in the execute_values() function below, more or less\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    execute_values(cur, query, values)\n",
    "\n",
    "conn.commit() # this makes all changes permanent after the connection closes\n",
    "\n",
    "# Now we've populated the table with our data subset and now we can query and thereby merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3d64869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a sample merge\n",
    "cur.execute(\"\"\"\n",
    "           SELECT a.url, a.political_leaning, a.title, a.gpt_topic, a.text_issue_frame, a.text_generic_frame,\n",
    "           b.maintext\n",
    "           FROM mm_framing_full a\n",
    "           JOIN newsarticles b\n",
    "            ON a.url = b.url \n",
    "            \"\"\")\n",
    "\n",
    "result= cur.fetchall()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a9f879f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://www.cbsnews.com/philadelphia/news/northern-snakeheads-invasive-fish-found-pennsylvania/',\n",
       " 'left_lean',\n",
       " 'Advisory issued for invasive fish in Pennsylvania that can survive outside of water',\n",
       " 'Environment',\n",
       " 'Environmental Threat',\n",
       " \"['Economic', 'Health and safety', 'Policy prescription and evaluation', 'External regulation and reputation']\",\n",
       " 'PITTSBURGH (KDKA) — The Pennsylvania Fish and Boat Commission has issued a \"strong advisory\" to anglers in Pennsylvania regarding an invasive fish.\\nIn a release on Wednesday, the agency encourages anyone who catches a northern snakehead anywhere in the state to report and dispose of it.\\n\"Northern Snakeheads are voracious predators and may cause declines in important sport fisheries, such as bass and panfish, and may inhibit recovery efforts for species of conservation concern in the region such as American Shad and Chesapeake Logperch,\" said Sean Hartzell of the Pennsylvania Fish and Boat Commission.\\nOfficials have been monitoring for northern snakeheads in the lower Susquehanna River since May 2020, the Pennsylvania Fish and Boat Commission said. The fish are tough, air-breathing fish that can survive outside of water for extended periods of time.\\n\"It is recommended to kill them by removal of the head, removal of the gill arches, or removal of the internal organs. Northern Snakeheads produce white meat fillets that are considered desirable table fare. Carcasses may also be disposed of appropriately in the trash or used as garden fertilizer,\" the Pennsylvania Fish and Boat Commission said in the release.\\nNorthern snakeheads were first discovered in the mid-Atlantic region in 2002 when they were found in a Maryland pond. Snakeheads were first confirmed in Pennsylvania in July 2004. The first northern snakehead was caught in the Monongahela River in 2019.')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)\n",
    "type(result)\n",
    "\n",
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "52f1c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423410bf",
   "metadata": {},
   "source": [
    "### Finishing the data preparation\n",
    "Next steps:\n",
    "* ensure data is in the right format (tensors)\n",
    "* tokenize the data, matching it to pytorch's transformers\n",
    "* generate the dataloader\n",
    "* Split the data along test_train_split (arrow df method available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63327a6c",
   "metadata": {},
   "source": [
    "### Training loop\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
